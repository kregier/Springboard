{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the environment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the data\n",
    "X_train = pd.read_csv('data/processed/X_train.csv', index_col=0)\n",
    "X_test = pd.read_csv('data/processed/X_test.csv', index_col=0)\n",
    "y_train = pd.read_csv('data/processed/y_train.csv', index_col=0)\n",
    "y_test = pd.read_csv('data/processed/y_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 55025 entries, 2905 to 78034\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   NUMBRANCH          55025 non-null  float64\n",
      " 1   UGDS               55025 non-null  float64\n",
      " 2   TUITFTE            55025 non-null  float64\n",
      " 3   INEXPFTE           55025 non-null  float64\n",
      " 4   PFTFAC             55025 non-null  float64\n",
      " 5   UG25abv            55025 non-null  float64\n",
      " 6   COMP_ORIG_YR4_RT   55025 non-null  float64\n",
      " 7   WDRAW_ORIG_YR4_RT  55025 non-null  float64\n",
      " 8   ENRL_ORIG_YR4_RT   55025 non-null  float64\n",
      " 9   DEBT_MDN           55025 non-null  float64\n",
      " 10  Year               55025 non-null  float64\n",
      " 11  Cost               55025 non-null  float64\n",
      " 12  Complete           55025 non-null  float64\n",
      " 13  RetentionFT        55025 non-null  float64\n",
      " 14  PREDDEG_1          55025 non-null  float64\n",
      " 15  PREDDEG_2          55025 non-null  float64\n",
      " 16  PREDDEG_3          55025 non-null  float64\n",
      " 17  PREDDEG_4          55025 non-null  float64\n",
      " 18  CONTROL_2.0        55025 non-null  float64\n",
      " 19  CONTROL_3.0        55025 non-null  float64\n",
      "dtypes: float64(20)\n",
      "memory usage: 8.8 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 55025 entries, 10080 to 62883\n",
      "Data columns (total 1 columns):\n",
      " #   Column    Non-Null Count  Dtype\n",
      "---  ------    --------------  -----\n",
      " 0   CURROPER  55025 non-null  bool \n",
      "dtypes: bool(1)\n",
      "memory usage: 483.6 KB\n"
     ]
    }
   ],
   "source": [
    "y_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_train.CURROPER.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "## Logistic Regression\n",
    "\n",
    "Hyperparameters to tune:\n",
    "- C - inverse of regularization strength; positive float; smaller values are stronger regularization, may lead to underfit model; large C may lead to overfitting\n",
    "- penalty (l1, l2, elasticnet, none) \n",
    "- l1_ratio - for elastic-net paramter mixing: l1_ratio = 0 == L2 penalty; l1_ratio = 1 == L1 penalty, so no need to use l1 and l2 as penalty parameters, since they will be encompassed in the elastic net values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and instantiate model\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "c_grid = [0.001, 0.01, 0.1, 1, 10]\n",
    "pen_grid = ['elasticnet']\n",
    "l1_ratio_grid = [0, 0.1, 0.25, 0.5, 0.75, 0.9, 1]\n",
    "max_iter_grid = [100, 500, 1000, 1500, 2000]\n",
    "\n",
    "lr_grid = {'C':c_grid, 'penalty':pen_grid, 'l1_ratio':l1_ratio_grid,'max_iter':max_iter_grid}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: trying to use pen_grid = ['none', 'elasticnet'] led to errors, since the l1_ratio parameter is only valid for elastic net penatly, not none. If I want to train a model with no penalty, I will have to run a separate Grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver = 'saga')\n",
    "logreg_cv = RandomizedSearchCV(logreg, lr_grid, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note - default solver 'lbfgs' can't handle elasticnet penalty.\n",
    "Note - with default max_iter = 100, kept getting ConvergenceWarning: The max_iter was reached which means the coef_ did not converge, so I added max_iter as a grid search parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_sag.py:330: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch Time: 421.37392687797546\n"
     ]
    }
   ],
   "source": [
    "start= time.time()\n",
    "logreg_cv.fit(X_train, y)\n",
    "end = time.time()\n",
    "print('GridSearch Time:', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'penalty': 'elasticnet', 'max_iter': 2000, 'l1_ratio': 1, 'C': 0.001}\n",
      "Best score:  0.8530486142662426\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params: \" , logreg_cv.best_params_)\n",
    "print(\"Best score: \", logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original run: l1_ratio=0.25, max_iter=2000, C=0.001\n",
    "Second run: l1_ratio=1, max_iter= 2000, C=0.001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit time =  3.768968105316162\n",
      "Predict time =  0.0050411224365234375\n"
     ]
    }
   ],
   "source": [
    "modelLR = LogisticRegression(C = 0.001, penalty = 'elasticnet', l1_ratio=0.25, max_iter = 2000, solver = 'saga')\n",
    "start = time.time()\n",
    "modelLR.fit(X_train, y)\n",
    "end = time.time()\n",
    "print(\"Fit time = \", end - start)\n",
    "\n",
    "start = time.time()\n",
    "lr_pred = modelLR.predict(X_test)\n",
    "end = time.time()\n",
    "print(\"Predict time = \", end - start)\n",
    "\n",
    "lr_pred_prob = modelLR.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    3  3463]\n",
      " [    5 20112]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.38      0.00      0.00      3466\n",
      "        True       0.85      1.00      0.92     20117\n",
      "\n",
      "    accuracy                           0.85     23583\n",
      "   macro avg       0.61      0.50      0.46     23583\n",
      "weighted avg       0.78      0.85      0.79     23583\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ROC curve\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "fpr, tpr, thresholds = roc_curve(y_test, lr_pred_prob)\n",
    "\n",
    "plt.plot( [0,1], [0,1], 'k--')\n",
    "plt.plot(fpr, tpr, label='Logistic Regression')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Logistic Regression ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC:  0.7748366229513491\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC: \", roc_auc_score(y_test, lr_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "Parameters to search:\n",
    "- max_features\n",
    "- max_depth\n",
    "- min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_grid = ['gini', 'entropy']\n",
    "max_depth_grid = ['None', 3, 5, 10, 20, 50, 75, 100]\n",
    "min_sample_split_grid = [2, 5, 10, 25, 50, 75, 100]\n",
    "min_samples_leaf_grid = [2, 5, 10, 25, 50]\n",
    "feature_grid = [\"auto\", \"log2\", 4, 5, 10, 12, 15, 20]\n",
    "\n",
    "dtc_grid = {'criterion': criterion_grid, \n",
    "              'max_depth':max_depth_grid,\n",
    "              'min_samples_split':min_sample_split_grid,\n",
    "              'min_samples_leaf':min_samples_leaf_grid,\n",
    "              'max_features':feature_grid }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=5, error_score=nan,\n",
       "                   estimator=DecisionTreeClassifier(ccp_alpha=0.0,\n",
       "                                                    class_weight=None,\n",
       "                                                    criterion='gini',\n",
       "                                                    max_depth=None,\n",
       "                                                    max_features=None,\n",
       "                                                    max_leaf_nodes=None,\n",
       "                                                    min_impurity_decrease=0.0,\n",
       "                                                    min_impurity_split=None,\n",
       "                                                    min_samples_leaf=1,\n",
       "                                                    min_samples_split=2,\n",
       "                                                    min_weight_fraction_leaf=0.0,\n",
       "                                                    presort='deprecated',\n",
       "                                                    random_state=None,\n",
       "                                                    splitter='best'),\n",
       "                   i...precated', n_iter=10, n_jobs=None,\n",
       "                   param_distributions={'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': ['None', 3, 5, 10, 20, 50,\n",
       "                                                      75, 100],\n",
       "                                        'max_features': ['auto', 'log2', 4, 5,\n",
       "                                                         10, 12, 15, 20],\n",
       "                                        'min_samples_leaf': [2, 5, 10, 25, 50],\n",
       "                                        'min_samples_split': [2, 5, 10, 25, 50,\n",
       "                                                              75, 100]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree_cv = RandomizedSearchCV(tree, dtc_grid, cv=5)\n",
    "tree_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'min_samples_split': 2, 'min_samples_leaf': 25, 'max_features': 20, 'max_depth': 20, 'criterion': 'entropy'}\n",
      "Best score:  0.8722944116310767\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params: \" , tree_cv.best_params_)\n",
    "print(\"Best score: \", tree_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First run: min_sample_split=2; min_samples_leaf=25; max_features=20, max_depth=20, criterion=entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='entropy',\n",
       "                       max_depth=20, max_features=20, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=25, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the decision tree using the identified hyperparameters\n",
    "modelDT = DecisionTreeClassifier(criterion='entropy', min_samples_split=2, min_samples_leaf=25, \n",
    "                                 max_features=20, max_depth=20)\n",
    "modelDT.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Text(154.57218255429026, 212.26285714285714, 'X[19] <= 0.13\\nentropy = 0.602\\nsamples = 55025\\nvalue = [8086, 46939]'),\n",
       " Text(79.6534175450212, 201.90857142857143, 'X[1] <= -0.307\\nentropy = 0.363\\nsamples = 31119\\nvalue = [2155, 28964]'),\n",
       " Text(55.180133818855936, 191.5542857142857, 'X[0] <= 1.652\\nentropy = 0.595\\nsamples = 11685\\nvalue = [1683, 10002]'),\n",
       " Text(32.82285746822034, 181.2, 'X[1] <= -0.468\\nentropy = 0.562\\nsamples = 11501\\nvalue = [1515, 9986]'),\n",
       " Text(6.945681355932204, 170.84571428571428, 'X[17] <= 2.366\\nentropy = 0.936\\nsamples = 995\\nvalue = [350, 645]'),\n",
       " Text(4.44886779661017, 160.49142857142857, 'X[10] <= 0.099\\nentropy = 0.974\\nsamples = 793\\nvalue = [321, 472]'),\n",
       " Text(2.3606237288135596, 150.13714285714286, 'X[11] <= -1.102\\nentropy = 1.0\\nsamples = 472\\nvalue = [231, 241]'),\n",
       " Text(1.634277966101695, 139.78285714285715, 'X[3] <= -0.005\\nentropy = 0.672\\nsamples = 51\\nvalue = [9, 42]'),\n",
       " Text(1.2711050847457628, 129.42857142857144, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(1.9974508474576274, 129.42857142857144, 'entropy = 0.89\\nsamples = 26\\nvalue = [8, 18]'),\n",
       " Text(3.0869694915254238, 139.78285714285715, 'X[6] <= 2.049\\nentropy = 0.998\\nsamples = 421\\nvalue = [222, 199]'),\n",
       " Text(2.723796610169492, 129.42857142857144, 'X[0] <= -0.213\\nentropy = 0.991\\nsamples = 395\\nvalue = [219, 176]'),\n",
       " Text(1.452691525423729, 119.07428571428571, 'X[11] <= -0.883\\nentropy = 1.0\\nsamples = 296\\nvalue = [149, 147]'),\n",
       " Text(0.7263457627118645, 108.72, 'X[12] <= 1.386\\nentropy = 0.796\\nsamples = 54\\nvalue = [41, 13]'),\n",
       " Text(0.36317288135593223, 98.36571428571429, 'entropy = 0.967\\nsamples = 28\\nvalue = [17, 11]'),\n",
       " Text(1.0895186440677966, 98.36571428571429, 'entropy = 0.391\\nsamples = 26\\nvalue = [24, 2]'),\n",
       " Text(2.1790372881355933, 108.72, 'X[11] <= -0.521\\nentropy = 0.992\\nsamples = 242\\nvalue = [108, 134]'),\n",
       " Text(1.8158644067796612, 98.36571428571429, 'entropy = 0.711\\nsamples = 36\\nvalue = [7, 29]'),\n",
       " Text(2.5422101694915256, 98.36571428571429, 'X[3] <= -0.009\\nentropy = 1.0\\nsamples = 206\\nvalue = [101, 105]'),\n",
       " Text(2.1790372881355933, 88.01142857142858, 'entropy = 0.845\\nsamples = 33\\nvalue = [9, 24]'),\n",
       " Text(2.905383050847458, 88.01142857142858, 'X[13] <= 0.629\\nentropy = 0.997\\nsamples = 173\\nvalue = [92, 81]'),\n",
       " Text(2.1790372881355933, 77.65714285714284, 'X[12] <= 0.994\\nentropy = 0.988\\nsamples = 115\\nvalue = [50, 65]'),\n",
       " Text(1.8158644067796612, 67.30285714285714, 'X[2] <= -0.017\\nentropy = 0.959\\nsamples = 84\\nvalue = [32, 52]'),\n",
       " Text(1.452691525423729, 56.94857142857143, 'X[3] <= -0.004\\nentropy = 0.877\\nsamples = 54\\nvalue = [16, 38]'),\n",
       " Text(1.0895186440677966, 46.59428571428572, 'entropy = 0.992\\nsamples = 29\\nvalue = [13, 16]'),\n",
       " Text(1.8158644067796612, 46.59428571428572, 'entropy = 0.529\\nsamples = 25\\nvalue = [3, 22]'),\n",
       " Text(2.1790372881355933, 56.94857142857143, 'entropy = 0.997\\nsamples = 30\\nvalue = [16, 14]'),\n",
       " Text(2.5422101694915256, 67.30285714285714, 'entropy = 0.981\\nsamples = 31\\nvalue = [18, 13]'),\n",
       " Text(3.6317288135593224, 77.65714285714284, 'X[6] <= 0.382\\nentropy = 0.85\\nsamples = 58\\nvalue = [42, 16]'),\n",
       " Text(3.26855593220339, 67.30285714285714, 'entropy = 0.987\\nsamples = 30\\nvalue = [17, 13]'),\n",
       " Text(3.9949016949152547, 67.30285714285714, 'entropy = 0.491\\nsamples = 28\\nvalue = [25, 3]'),\n",
       " Text(3.9949016949152547, 119.07428571428571, 'X[3] <= -0.005\\nentropy = 0.872\\nsamples = 99\\nvalue = [70, 29]'),\n",
       " Text(3.6317288135593224, 108.72, 'X[4] <= 0.941\\nentropy = 0.636\\nsamples = 56\\nvalue = [47, 9]'),\n",
       " Text(3.26855593220339, 98.36571428571429, 'entropy = 0.229\\nsamples = 27\\nvalue = [26, 1]'),\n",
       " Text(3.9949016949152547, 98.36571428571429, 'entropy = 0.85\\nsamples = 29\\nvalue = [21, 8]'),\n",
       " Text(4.3580745762711866, 108.72, 'entropy = 0.996\\nsamples = 43\\nvalue = [23, 20]'),\n",
       " Text(3.450142372881356, 129.42857142857144, 'entropy = 0.516\\nsamples = 26\\nvalue = [3, 23]'),\n",
       " Text(6.53711186440678, 150.13714285714286, 'X[14] <= 0.157\\nentropy = 0.856\\nsamples = 321\\nvalue = [90, 231]'),\n",
       " Text(5.447593220338984, 139.78285714285715, 'X[2] <= 0.005\\nentropy = 0.515\\nsamples = 87\\nvalue = [10, 77]'),\n",
       " Text(5.084420338983051, 129.42857142857144, 'X[1] <= -0.47\\nentropy = 0.677\\nsamples = 56\\nvalue = [10, 46]'),\n",
       " Text(4.721247457627119, 119.07428571428571, 'entropy = 0.904\\nsamples = 25\\nvalue = [8, 17]'),\n",
       " Text(5.447593220338984, 119.07428571428571, 'entropy = 0.345\\nsamples = 31\\nvalue = [2, 29]'),\n",
       " Text(5.810766101694916, 129.42857142857144, 'entropy = 0.0\\nsamples = 31\\nvalue = [0, 31]'),\n",
       " Text(7.626630508474577, 139.78285714285715, 'X[6] <= -1.197\\nentropy = 0.927\\nsamples = 234\\nvalue = [80, 154]'),\n",
       " Text(6.53711186440678, 129.42857142857144, 'X[10] <= 0.73\\nentropy = 0.668\\nsamples = 103\\nvalue = [18, 85]'),\n",
       " Text(6.1739389830508475, 119.07428571428571, 'entropy = 0.902\\nsamples = 44\\nvalue = [14, 30]'),\n",
       " Text(6.900284745762712, 119.07428571428571, 'X[2] <= -0.103\\nentropy = 0.358\\nsamples = 59\\nvalue = [4, 55]'),\n",
       " Text(6.53711186440678, 108.72, 'entropy = 0.0\\nsamples = 34\\nvalue = [0, 34]'),\n",
       " Text(7.263457627118645, 108.72, 'entropy = 0.634\\nsamples = 25\\nvalue = [4, 21]'),\n",
       " Text(8.716149152542373, 129.42857142857144, 'X[6] <= 1.48\\nentropy = 0.998\\nsamples = 131\\nvalue = [62, 69]'),\n",
       " Text(8.352976271186442, 119.07428571428571, 'X[0] <= -0.213\\nentropy = 0.997\\nsamples = 105\\nvalue = [56, 49]'),\n",
       " Text(7.989803389830509, 108.72, 'X[2] <= -0.048\\nentropy = 0.989\\nsamples = 73\\nvalue = [32, 41]'),\n",
       " Text(7.626630508474577, 98.36571428571429, 'entropy = 0.918\\nsamples = 45\\nvalue = [15, 30]'),\n",
       " Text(8.352976271186442, 98.36571428571429, 'entropy = 0.967\\nsamples = 28\\nvalue = [17, 11]'),\n",
       " Text(8.716149152542373, 108.72, 'entropy = 0.811\\nsamples = 32\\nvalue = [24, 8]'),\n",
       " Text(9.079322033898306, 119.07428571428571, 'entropy = 0.779\\nsamples = 26\\nvalue = [6, 20]'),\n",
       " Text(9.442494915254239, 160.49142857142857, 'X[5] <= 0.259\\nentropy = 0.593\\nsamples = 202\\nvalue = [29, 173]'),\n",
       " Text(8.716149152542373, 150.13714285714286, 'X[5] <= -1.109\\nentropy = 0.861\\nsamples = 74\\nvalue = [21, 53]'),\n",
       " Text(8.352976271186442, 139.78285714285715, 'entropy = 0.0\\nsamples = 26\\nvalue = [0, 26]'),\n",
       " Text(9.079322033898306, 139.78285714285715, 'entropy = 0.989\\nsamples = 48\\nvalue = [21, 27]'),\n",
       " Text(10.168840677966102, 150.13714285714286, 'X[5] <= 1.83\\nentropy = 0.337\\nsamples = 128\\nvalue = [8, 120]'),\n",
       " Text(9.80566779661017, 139.78285714285715, 'X[2] <= -0.013\\nentropy = 0.091\\nsamples = 87\\nvalue = [1, 86]'),\n",
       " Text(9.442494915254239, 129.42857142857144, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(10.168840677966102, 129.42857142857144, 'entropy = 0.0\\nsamples = 62\\nvalue = [0, 62]'),\n",
       " Text(10.532013559322035, 139.78285714285715, 'entropy = 0.659\\nsamples = 41\\nvalue = [7, 34]'),\n",
       " Text(58.70003358050848, 170.84571428571428, 'X[0] <= -0.213\\nentropy = 0.503\\nsamples = 10506\\nvalue = [1165, 9341]'),\n",
       " Text(44.2661281779661, 160.49142857142857, 'X[10] <= 0.099\\nentropy = 0.441\\nsamples = 8763\\nvalue = [801, 7962]'),\n",
       " Text(27.32060211864407, 150.13714285714286, 'X[8] <= 1.134\\nentropy = 0.534\\nsamples = 4827\\nvalue = [587, 4240]'),\n",
       " Text(22.019483898305086, 139.78285714285715, 'X[11] <= -0.337\\nentropy = 0.551\\nsamples = 4553\\nvalue = [582, 3971]'),\n",
       " Text(12.506766101694916, 129.42857142857144, 'X[2] <= -0.163\\nentropy = 0.469\\nsamples = 2541\\nvalue = [254, 2287]'),\n",
       " Text(9.987254237288136, 119.07428571428571, 'X[3] <= -0.009\\nentropy = 0.933\\nsamples = 63\\nvalue = [22, 41]'),\n",
       " Text(9.624081355932205, 108.72, 'entropy = 0.998\\nsamples = 36\\nvalue = [19, 17]'),\n",
       " Text(10.350427118644069, 108.72, 'entropy = 0.503\\nsamples = 27\\nvalue = [3, 24]'),\n",
       " Text(15.026277966101697, 119.07428571428571, 'X[11] <= -0.94\\nentropy = 0.448\\nsamples = 2478\\nvalue = [232, 2246]'),\n",
       " Text(11.076772881355932, 108.72, 'X[11] <= -0.941\\nentropy = 0.565\\nsamples = 814\\nvalue = [108, 706]'),\n",
       " Text(9.079322033898306, 98.36571428571429, 'X[2] <= -0.113\\nentropy = 0.394\\nsamples = 604\\nvalue = [47, 557]'),\n",
       " Text(7.626630508474577, 88.01142857142858, 'X[1] <= -0.316\\nentropy = 0.199\\nsamples = 388\\nvalue = [12, 376]'),\n",
       " Text(7.263457627118645, 77.65714285714284, 'X[3] <= -0.007\\nentropy = 0.153\\nsamples = 363\\nvalue = [8, 355]'),\n",
       " Text(6.53711186440678, 67.30285714285714, 'X[5] <= -0.944\\nentropy = 0.037\\nsamples = 258\\nvalue = [1, 257]'),\n",
       " Text(6.1739389830508475, 56.94857142857143, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(6.900284745762712, 56.94857142857143, 'entropy = 0.0\\nsamples = 233\\nvalue = [0, 233]'),\n",
       " Text(7.989803389830509, 67.30285714285714, 'X[1] <= -0.422\\nentropy = 0.353\\nsamples = 105\\nvalue = [7, 98]'),\n",
       " Text(7.626630508474577, 56.94857142857143, 'X[6] <= -1.165\\nentropy = 0.525\\nsamples = 59\\nvalue = [7, 52]'),\n",
       " Text(7.263457627118645, 46.59428571428572, 'entropy = 0.191\\nsamples = 34\\nvalue = [1, 33]'),\n",
       " Text(7.989803389830509, 46.59428571428572, 'entropy = 0.795\\nsamples = 25\\nvalue = [6, 19]'),\n",
       " Text(8.352976271186442, 56.94857142857143, 'entropy = 0.0\\nsamples = 46\\nvalue = [0, 46]'),\n",
       " Text(7.989803389830509, 77.65714285714284, 'entropy = 0.634\\nsamples = 25\\nvalue = [4, 21]'),\n",
       " Text(10.532013559322035, 88.01142857142858, 'X[11] <= -1.047\\nentropy = 0.639\\nsamples = 216\\nvalue = [35, 181]'),\n",
       " Text(10.168840677966102, 77.65714285714284, 'X[11] <= -1.139\\nentropy = 0.823\\nsamples = 136\\nvalue = [35, 101]'),\n",
       " Text(9.442494915254239, 67.30285714285714, 'X[11] <= -1.307\\nentropy = 0.631\\nsamples = 82\\nvalue = [13, 69]'),\n",
       " Text(9.079322033898306, 56.94857142857143, 'entropy = 0.901\\nsamples = 41\\nvalue = [13, 28]'),\n",
       " Text(9.80566779661017, 56.94857142857143, 'entropy = 0.0\\nsamples = 41\\nvalue = [0, 41]'),\n",
       " Text(10.895186440677968, 67.30285714285714, 'X[3] <= -0.008\\nentropy = 0.975\\nsamples = 54\\nvalue = [22, 32]'),\n",
       " Text(10.532013559322035, 56.94857142857143, 'entropy = 0.579\\nsamples = 29\\nvalue = [4, 25]'),\n",
       " Text(11.258359322033899, 56.94857142857143, 'entropy = 0.855\\nsamples = 25\\nvalue = [18, 7]'),\n",
       " Text(10.895186440677968, 77.65714285714284, 'entropy = 0.0\\nsamples = 80\\nvalue = [0, 80]'),\n",
       " Text(13.07422372881356, 98.36571428571429, 'X[5] <= 0.134\\nentropy = 0.869\\nsamples = 210\\nvalue = [61, 149]'),\n",
       " Text(12.711050847457628, 88.01142857142858, 'entropy = 0.952\\nsamples = 43\\nvalue = [27, 16]'),\n",
       " Text(13.437396610169493, 88.01142857142858, 'X[1] <= -0.43\\nentropy = 0.729\\nsamples = 167\\nvalue = [34, 133]'),\n",
       " Text(13.07422372881356, 77.65714285714284, 'X[1] <= -0.459\\nentropy = 0.544\\nsamples = 120\\nvalue = [15, 105]'),\n",
       " Text(12.347877966101695, 67.30285714285714, 'X[2] <= -0.103\\nentropy = 0.742\\nsamples = 57\\nvalue = [12, 45]'),\n",
       " Text(11.984705084745764, 56.94857142857143, 'entropy = 0.904\\nsamples = 25\\nvalue = [8, 17]'),\n",
       " Text(12.711050847457628, 56.94857142857143, 'entropy = 0.544\\nsamples = 32\\nvalue = [4, 28]'),\n",
       " Text(13.800569491525424, 67.30285714285714, 'X[5] <= 1.213\\nentropy = 0.276\\nsamples = 63\\nvalue = [3, 60]'),\n",
       " Text(13.437396610169493, 56.94857142857143, 'entropy = 0.0\\nsamples = 38\\nvalue = [0, 38]'),\n",
       " Text(14.163742372881357, 56.94857142857143, 'entropy = 0.529\\nsamples = 25\\nvalue = [3, 22]'),\n",
       " Text(13.800569491525424, 77.65714285714284, 'entropy = 0.973\\nsamples = 47\\nvalue = [19, 28]'),\n",
       " Text(18.975783050847458, 108.72, 'X[6] <= -0.937\\nentropy = 0.383\\nsamples = 1664\\nvalue = [124, 1540]'),\n",
       " Text(15.979606779661019, 98.36571428571429, 'X[5] <= 1.406\\nentropy = 0.177\\nsamples = 488\\nvalue = [13, 475]'),\n",
       " Text(15.616433898305086, 88.01142857142858, 'X[5] <= 0.025\\nentropy = 0.104\\nsamples = 442\\nvalue = [6, 436]'),\n",
       " Text(15.253261016949153, 77.65714285714284, 'entropy = 0.0\\nsamples = 223\\nvalue = [0, 223]'),\n",
       " Text(15.979606779661019, 77.65714285714284, 'X[18] <= 0.514\\nentropy = 0.181\\nsamples = 219\\nvalue = [6, 213]'),\n",
       " Text(15.253261016949153, 67.30285714285714, 'X[3] <= -0.009\\nentropy = 0.054\\nsamples = 164\\nvalue = [1, 163]'),\n",
       " Text(14.89008813559322, 56.94857142857143, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(15.616433898305086, 56.94857142857143, 'entropy = 0.0\\nsamples = 139\\nvalue = [0, 139]'),\n",
       " Text(16.705952542372884, 67.30285714285714, 'X[2] <= -0.046\\nentropy = 0.439\\nsamples = 55\\nvalue = [5, 50]'),\n",
       " Text(16.34277966101695, 56.94857142857143, 'entropy = 0.634\\nsamples = 25\\nvalue = [4, 21]'),\n",
       " Text(17.069125423728813, 56.94857142857143, 'entropy = 0.211\\nsamples = 30\\nvalue = [1, 29]'),\n",
       " Text(16.34277966101695, 88.01142857142858, 'entropy = 0.615\\nsamples = 46\\nvalue = [7, 39]'),\n",
       " Text(21.9719593220339, 98.36571428571429, 'X[2] <= -0.134\\nentropy = 0.451\\nsamples = 1176\\nvalue = [111, 1065]'),\n",
       " Text(21.608786440677967, 88.01142857142858, 'entropy = 0.0\\nsamples = 88\\nvalue = [0, 88]'),\n",
       " Text(22.335132203389833, 88.01142857142858, 'X[3] <= -0.001\\nentropy = 0.475\\nsamples = 1088\\nvalue = [111, 977]'),\n",
       " Text(19.792922033898307, 77.65714285714284, 'X[7] <= 0.225\\nentropy = 0.398\\nsamples = 736\\nvalue = [58, 678]'),\n",
       " Text(19.429749152542374, 67.30285714285714, 'X[6] <= 0.424\\nentropy = 0.435\\nsamples = 647\\nvalue = [58, 589]'),\n",
       " Text(17.79547118644068, 56.94857142857143, 'X[11] <= -0.612\\nentropy = 0.737\\nsamples = 106\\nvalue = [22, 84]'),\n",
       " Text(17.069125423728813, 46.59428571428572, 'X[12] <= -0.085\\nentropy = 0.905\\nsamples = 53\\nvalue = [17, 36]'),\n",
       " Text(16.705952542372884, 36.24000000000001, 'entropy = 1.0\\nsamples = 26\\nvalue = [13, 13]'),\n",
       " Text(17.432298305084746, 36.24000000000001, 'entropy = 0.605\\nsamples = 27\\nvalue = [4, 23]'),\n",
       " Text(18.521816949152544, 46.59428571428572, 'X[6] <= 0.06\\nentropy = 0.451\\nsamples = 53\\nvalue = [5, 48]'),\n",
       " Text(18.15864406779661, 36.24000000000001, 'entropy = 0.0\\nsamples = 28\\nvalue = [0, 28]'),\n",
       " Text(18.884989830508477, 36.24000000000001, 'entropy = 0.722\\nsamples = 25\\nvalue = [5, 20]'),\n",
       " Text(21.06402711864407, 56.94857142857143, 'X[4] <= -0.638\\nentropy = 0.353\\nsamples = 541\\nvalue = [36, 505]'),\n",
       " Text(19.97450847457627, 46.59428571428572, 'X[5] <= -0.777\\nentropy = 0.068\\nsamples = 123\\nvalue = [1, 122]'),\n",
       " Text(19.61133559322034, 36.24000000000001, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(20.337681355932204, 36.24000000000001, 'entropy = 0.0\\nsamples = 98\\nvalue = [0, 98]'),\n",
       " Text(22.153545762711865, 46.59428571428572, 'X[4] <= 0.156\\nentropy = 0.415\\nsamples = 418\\nvalue = [35, 383]'),\n",
       " Text(21.06402711864407, 36.24000000000001, 'X[3] <= -0.008\\nentropy = 0.611\\nsamples = 113\\nvalue = [17, 96]'),\n",
       " Text(20.700854237288137, 25.8857142857143, 'entropy = 0.201\\nsamples = 32\\nvalue = [1, 31]'),\n",
       " Text(21.427200000000003, 25.8857142857143, 'X[5] <= 0.387\\nentropy = 0.717\\nsamples = 81\\nvalue = [16, 65]'),\n",
       " Text(21.06402711864407, 15.531428571428563, 'X[2] <= 0.001\\nentropy = 0.592\\nsamples = 56\\nvalue = [8, 48]'),\n",
       " Text(20.700854237288137, 5.177142857142854, 'entropy = 0.0\\nsamples = 26\\nvalue = [0, 26]'),\n",
       " Text(21.427200000000003, 5.177142857142854, 'entropy = 0.837\\nsamples = 30\\nvalue = [8, 22]'),\n",
       " Text(21.790372881355935, 15.531428571428563, 'entropy = 0.904\\nsamples = 25\\nvalue = [8, 17]'),\n",
       " Text(23.243064406779663, 36.24000000000001, 'X[2] <= 0.016\\nentropy = 0.324\\nsamples = 305\\nvalue = [18, 287]'),\n",
       " Text(22.87989152542373, 25.8857142857143, 'X[5] <= -1.334\\nentropy = 0.407\\nsamples = 221\\nvalue = [18, 203]'),\n",
       " Text(22.516718644067797, 15.531428571428563, 'entropy = 0.0\\nsamples = 45\\nvalue = [0, 45]'),\n",
       " Text(23.243064406779663, 15.531428571428563, 'X[2] <= -0.079\\nentropy = 0.476\\nsamples = 176\\nvalue = [18, 158]'),\n",
       " Text(22.87989152542373, 5.177142857142854, 'entropy = 0.25\\nsamples = 96\\nvalue = [4, 92]'),\n",
       " Text(23.606237288135596, 5.177142857142854, 'entropy = 0.669\\nsamples = 80\\nvalue = [14, 66]'),\n",
       " Text(23.606237288135596, 25.8857142857143, 'entropy = 0.0\\nsamples = 84\\nvalue = [0, 84]'),\n",
       " Text(20.15609491525424, 67.30285714285714, 'entropy = 0.0\\nsamples = 89\\nvalue = [0, 89]'),\n",
       " Text(24.87734237288136, 77.65714285714284, 'X[9] <= -1.199\\nentropy = 0.611\\nsamples = 352\\nvalue = [53, 299]'),\n",
       " Text(24.514169491525426, 67.30285714285714, 'entropy = 0.0\\nsamples = 54\\nvalue = [0, 54]'),\n",
       " Text(25.24051525423729, 67.30285714285714, 'X[5] <= -1.386\\nentropy = 0.675\\nsamples = 298\\nvalue = [53, 245]'),\n",
       " Text(24.33258305084746, 56.94857142857143, 'X[5] <= -1.707\\nentropy = 0.216\\nsamples = 58\\nvalue = [2, 56]'),\n",
       " Text(23.96941016949153, 46.59428571428572, 'entropy = 0.402\\nsamples = 25\\nvalue = [2, 23]'),\n",
       " Text(24.69575593220339, 46.59428571428572, 'entropy = 0.0\\nsamples = 33\\nvalue = [0, 33]'),\n",
       " Text(26.14844745762712, 56.94857142857143, 'X[1] <= -0.46\\nentropy = 0.746\\nsamples = 240\\nvalue = [51, 189]'),\n",
       " Text(25.422101694915256, 46.59428571428572, 'X[6] <= 0.973\\nentropy = 0.827\\nsamples = 173\\nvalue = [45, 128]'),\n",
       " Text(25.058928813559323, 36.24000000000001, 'X[5] <= 0.46\\nentropy = 0.878\\nsamples = 131\\nvalue = [39, 92]'),\n",
       " Text(24.33258305084746, 25.8857142857143, 'X[3] <= 0.007\\nentropy = 0.774\\nsamples = 79\\nvalue = [18, 61]'),\n",
       " Text(23.96941016949153, 15.531428571428563, 'entropy = 0.446\\nsamples = 43\\nvalue = [4, 39]'),\n",
       " Text(24.69575593220339, 15.531428571428563, 'entropy = 0.964\\nsamples = 36\\nvalue = [14, 22]'),\n",
       " Text(25.78527457627119, 25.8857142857143, 'X[4] <= 0.19\\nentropy = 0.973\\nsamples = 52\\nvalue = [21, 31]'),\n",
       " Text(25.422101694915256, 15.531428571428563, 'entropy = 0.795\\nsamples = 25\\nvalue = [6, 19]'),\n",
       " Text(26.14844745762712, 15.531428571428563, 'entropy = 0.991\\nsamples = 27\\nvalue = [15, 12]'),\n",
       " Text(25.78527457627119, 36.24000000000001, 'entropy = 0.592\\nsamples = 42\\nvalue = [6, 36]'),\n",
       " Text(26.874793220338987, 46.59428571428572, 'X[9] <= 0.282\\nentropy = 0.435\\nsamples = 67\\nvalue = [6, 61]'),\n",
       " Text(26.511620338983054, 36.24000000000001, 'entropy = 0.0\\nsamples = 25\\nvalue = [0, 25]'),\n",
       " Text(27.237966101694916, 36.24000000000001, 'entropy = 0.592\\nsamples = 42\\nvalue = [6, 36]'),\n",
       " Text(31.53220169491526, 129.42857142857144, 'X[11] <= -0.31\\nentropy = 0.641\\nsamples = 2012\\nvalue = [328, 1684]'),\n",
       " Text(26.69320677966102, 119.07428571428571, 'X[3] <= -0.01\\nentropy = 0.959\\nsamples = 291\\nvalue = [111, 180]'),\n",
       " Text(26.330033898305086, 108.72, 'entropy = 0.888\\nsamples = 36\\nvalue = [25, 11]'),\n",
       " Text(27.05637966101695, 108.72, 'X[5] <= 1.732\\nentropy = 0.922\\nsamples = 255\\nvalue = [86, 169]'),\n",
       " Text(26.69320677966102, 98.36571428571429, 'X[1] <= -0.466\\nentropy = 0.869\\nsamples = 217\\nvalue = [63, 154]'),\n",
       " Text(26.330033898305086, 88.01142857142858, 'entropy = 0.968\\nsamples = 38\\nvalue = [23, 15]'),\n",
       " Text(27.05637966101695, 88.01142857142858, 'X[12] <= 0.569\\nentropy = 0.766\\nsamples = 179\\nvalue = [40, 139]'),\n",
       " Text(26.330033898305086, 77.65714285714284, 'X[3] <= -0.006\\nentropy = 0.987\\nsamples = 60\\nvalue = [26, 34]'),\n",
       " Text(25.966861016949153, 67.30285714285714, 'entropy = 0.961\\nsamples = 26\\nvalue = [16, 10]'),\n",
       " Text(26.69320677966102, 67.30285714285714, 'entropy = 0.874\\nsamples = 34\\nvalue = [10, 24]'),\n",
       " Text(27.782725423728817, 77.65714285714284, 'X[2] <= -0.079\\nentropy = 0.523\\nsamples = 119\\nvalue = [14, 105]'),\n",
       " Text(27.419552542372884, 67.30285714285714, 'X[5] <= 0.856\\nentropy = 0.183\\nsamples = 72\\nvalue = [2, 70]'),\n",
       " Text(27.05637966101695, 56.94857142857143, 'entropy = 0.0\\nsamples = 46\\nvalue = [0, 46]'),\n",
       " Text(27.782725423728817, 56.94857142857143, 'entropy = 0.391\\nsamples = 26\\nvalue = [2, 24]'),\n",
       " Text(28.14589830508475, 67.30285714285714, 'entropy = 0.82\\nsamples = 47\\nvalue = [12, 35]'),\n",
       " Text(27.419552542372884, 98.36571428571429, 'entropy = 0.968\\nsamples = 38\\nvalue = [23, 15]'),\n",
       " Text(36.37119661016949, 119.07428571428571, 'X[6] <= 0.399\\nentropy = 0.547\\nsamples = 1721\\nvalue = [217, 1504]'),\n",
       " Text(31.703857627118648, 108.72, 'X[11] <= 0.042\\nentropy = 0.635\\nsamples = 1142\\nvalue = [183, 959]'),\n",
       " Text(30.324935593220342, 98.36571428571429, 'X[15] <= 0.725\\nentropy = 0.338\\nsamples = 255\\nvalue = [16, 239]'),\n",
       " Text(29.96176271186441, 88.01142857142858, 'X[2] <= -0.018\\nentropy = 0.187\\nsamples = 210\\nvalue = [6, 204]'),\n",
       " Text(29.235416949152544, 77.65714285714284, 'X[5] <= 1.115\\nentropy = 0.057\\nsamples = 154\\nvalue = [1, 153]'),\n",
       " Text(28.87224406779661, 67.30285714285714, 'entropy = 0.0\\nsamples = 129\\nvalue = [0, 129]'),\n",
       " Text(29.598589830508477, 67.30285714285714, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(30.688108474576275, 77.65714285714284, 'X[3] <= -0.005\\nentropy = 0.434\\nsamples = 56\\nvalue = [5, 51]'),\n",
       " Text(30.324935593220342, 67.30285714285714, 'entropy = 0.722\\nsamples = 25\\nvalue = [5, 20]'),\n",
       " Text(31.051281355932204, 67.30285714285714, 'entropy = 0.0\\nsamples = 31\\nvalue = [0, 31]'),\n",
       " Text(30.688108474576275, 88.01142857142858, 'entropy = 0.764\\nsamples = 45\\nvalue = [10, 35]'),\n",
       " Text(33.08277966101695, 98.36571428571429, 'X[11] <= 0.082\\nentropy = 0.698\\nsamples = 887\\nvalue = [167, 720]'),\n",
       " Text(32.71960677966102, 88.01142857142858, 'entropy = 1.0\\nsamples = 47\\nvalue = [24, 23]'),\n",
       " Text(33.445952542372886, 88.01142857142858, 'X[1] <= -0.461\\nentropy = 0.658\\nsamples = 840\\nvalue = [143, 697]'),\n",
       " Text(32.140800000000006, 77.65714285714284, 'X[13] <= -0.525\\nentropy = 0.969\\nsamples = 73\\nvalue = [29, 44]'),\n",
       " Text(31.77762711864407, 67.30285714285714, 'entropy = 0.734\\nsamples = 34\\nvalue = [7, 27]'),\n",
       " Text(32.503972881355935, 67.30285714285714, 'entropy = 0.988\\nsamples = 39\\nvalue = [22, 17]'),\n",
       " Text(34.75110508474577, 77.65714285714284, 'X[11] <= 0.205\\nentropy = 0.606\\nsamples = 767\\nvalue = [114, 653]'),\n",
       " Text(33.2303186440678, 67.30285714285714, 'X[5] <= -0.506\\nentropy = 0.232\\nsamples = 106\\nvalue = [4, 102]'),\n",
       " Text(32.867145762711864, 56.94857142857143, 'entropy = 0.0\\nsamples = 61\\nvalue = [0, 61]'),\n",
       " Text(33.59349152542373, 56.94857142857143, 'entropy = 0.433\\nsamples = 45\\nvalue = [4, 41]'),\n",
       " Text(36.27189152542373, 67.30285714285714, 'X[11] <= 0.374\\nentropy = 0.649\\nsamples = 661\\nvalue = [110, 551]'),\n",
       " Text(34.319837288135595, 56.94857142857143, 'X[5] <= -0.894\\nentropy = 0.94\\nsamples = 101\\nvalue = [36, 65]'),\n",
       " Text(33.956664406779666, 46.59428571428572, 'entropy = 0.559\\nsamples = 46\\nvalue = [6, 40]'),\n",
       " Text(34.68301016949153, 46.59428571428572, 'X[1] <= -0.413\\nentropy = 0.994\\nsamples = 55\\nvalue = [30, 25]'),\n",
       " Text(34.319837288135595, 36.24000000000001, 'entropy = 0.826\\nsamples = 27\\nvalue = [7, 20]'),\n",
       " Text(35.04618305084746, 36.24000000000001, 'entropy = 0.677\\nsamples = 28\\nvalue = [23, 5]'),\n",
       " Text(38.223945762711864, 56.94857142857143, 'X[1] <= -0.429\\nentropy = 0.563\\nsamples = 560\\nvalue = [74, 486]'),\n",
       " Text(36.49887457627119, 46.59428571428572, 'X[12] <= -0.247\\nentropy = 0.791\\nsamples = 164\\nvalue = [39, 125]'),\n",
       " Text(35.772528813559326, 36.24000000000001, 'X[8] <= -0.229\\nentropy = 0.989\\nsamples = 66\\nvalue = [29, 37]'),\n",
       " Text(35.40935593220339, 25.8857142857143, 'entropy = 0.722\\nsamples = 25\\nvalue = [5, 20]'),\n",
       " Text(36.135701694915255, 25.8857142857143, 'entropy = 0.979\\nsamples = 41\\nvalue = [24, 17]'),\n",
       " Text(37.22522033898306, 36.24000000000001, 'X[3] <= -0.003\\nentropy = 0.475\\nsamples = 98\\nvalue = [10, 88]'),\n",
       " Text(36.86204745762712, 25.8857142857143, 'X[12] <= 0.468\\nentropy = 0.619\\nsamples = 65\\nvalue = [10, 55]'),\n",
       " Text(36.49887457627119, 15.531428571428563, 'entropy = 0.769\\nsamples = 40\\nvalue = [9, 31]'),\n",
       " Text(37.22522033898306, 15.531428571428563, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(37.588393220338986, 25.8857142857143, 'entropy = 0.0\\nsamples = 33\\nvalue = [0, 33]'),\n",
       " Text(39.94901694915254, 46.59428571428572, 'X[3] <= -0.004\\nentropy = 0.431\\nsamples = 396\\nvalue = [35, 361]'),\n",
       " Text(39.04108474576272, 36.24000000000001, 'X[9] <= 0.322\\nentropy = 0.511\\nsamples = 299\\nvalue = [34, 265]'),\n",
       " Text(38.31473898305085, 25.8857142857143, 'X[7] <= 0.828\\nentropy = 0.658\\nsamples = 147\\nvalue = [25, 122]'),\n",
       " Text(37.951566101694915, 15.531428571428563, 'X[5] <= -1.494\\nentropy = 0.541\\nsamples = 121\\nvalue = [15, 106]'),\n",
       " Text(37.588393220338986, 5.177142857142854, 'entropy = 0.176\\nsamples = 38\\nvalue = [1, 37]'),\n",
       " Text(38.31473898305085, 5.177142857142854, 'entropy = 0.655\\nsamples = 83\\nvalue = [14, 69]'),\n",
       " Text(38.67791186440678, 15.531428571428563, 'entropy = 0.961\\nsamples = 26\\nvalue = [10, 16]'),\n",
       " Text(39.76743050847458, 25.8857142857143, 'X[3] <= -0.005\\nentropy = 0.324\\nsamples = 152\\nvalue = [9, 143]'),\n",
       " Text(39.404257627118646, 15.531428571428563, 'X[11] <= 0.812\\nentropy = 0.161\\nsamples = 127\\nvalue = [3, 124]'),\n",
       " Text(39.04108474576272, 5.177142857142854, 'entropy = 0.391\\nsamples = 39\\nvalue = [3, 36]'),\n",
       " Text(39.76743050847458, 5.177142857142854, 'entropy = 0.0\\nsamples = 88\\nvalue = [0, 88]'),\n",
       " Text(40.13060338983051, 15.531428571428563, 'entropy = 0.795\\nsamples = 25\\nvalue = [6, 19]'),\n",
       " Text(40.85694915254238, 36.24000000000001, 'X[6] <= -0.612\\nentropy = 0.083\\nsamples = 97\\nvalue = [1, 96]'),\n",
       " Text(40.49377627118644, 25.8857142857143, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(41.220122033898306, 25.8857142857143, 'entropy = 0.0\\nsamples = 72\\nvalue = [0, 72]'),\n",
       " Text(41.038535593220345, 108.72, 'X[1] <= -0.454\\nentropy = 0.322\\nsamples = 579\\nvalue = [34, 545]'),\n",
       " Text(40.13060338983051, 98.36571428571429, 'X[4] <= 1.159\\nentropy = 0.717\\nsamples = 81\\nvalue = [16, 65]'),\n",
       " Text(39.76743050847458, 88.01142857142858, 'X[5] <= 0.733\\nentropy = 0.397\\nsamples = 51\\nvalue = [4, 47]'),\n",
       " Text(39.404257627118646, 77.65714285714284, 'entropy = 0.634\\nsamples = 25\\nvalue = [4, 21]'),\n",
       " Text(40.13060338983051, 77.65714285714284, 'entropy = 0.0\\nsamples = 26\\nvalue = [0, 26]'),\n",
       " Text(40.49377627118644, 88.01142857142858, 'entropy = 0.971\\nsamples = 30\\nvalue = [12, 18]'),\n",
       " Text(41.94646779661017, 98.36571428571429, 'X[3] <= -0.003\\nentropy = 0.224\\nsamples = 498\\nvalue = [18, 480]'),\n",
       " Text(41.58329491525424, 88.01142857142858, 'X[2] <= 0.043\\nentropy = 0.299\\nsamples = 339\\nvalue = [18, 321]'),\n",
       " Text(40.85694915254238, 77.65714285714284, 'X[13] <= -0.527\\nentropy = 0.199\\nsamples = 259\\nvalue = [8, 251]'),\n",
       " Text(40.49377627118644, 67.30285714285714, 'entropy = 0.0\\nsamples = 75\\nvalue = [0, 75]'),\n",
       " Text(41.220122033898306, 67.30285714285714, 'X[4] <= -0.809\\nentropy = 0.258\\nsamples = 184\\nvalue = [8, 176]'),\n",
       " Text(40.85694915254238, 56.94857142857143, 'entropy = 0.634\\nsamples = 25\\nvalue = [4, 21]'),\n",
       " Text(41.58329491525424, 56.94857142857143, 'X[11] <= 0.347\\nentropy = 0.169\\nsamples = 159\\nvalue = [4, 155]'),\n",
       " Text(41.220122033898306, 46.59428571428572, 'entropy = 0.0\\nsamples = 74\\nvalue = [0, 74]'),\n",
       " Text(41.94646779661017, 46.59428571428572, 'X[6] <= 1.064\\nentropy = 0.274\\nsamples = 85\\nvalue = [4, 81]'),\n",
       " Text(41.58329491525424, 36.24000000000001, 'entropy = 0.446\\nsamples = 43\\nvalue = [4, 39]'),\n",
       " Text(42.30964067796611, 36.24000000000001, 'entropy = 0.0\\nsamples = 42\\nvalue = [0, 42]'),\n",
       " Text(42.30964067796611, 77.65714285714284, 'X[2] <= 0.076\\nentropy = 0.544\\nsamples = 80\\nvalue = [10, 70]'),\n",
       " Text(41.94646779661017, 67.30285714285714, 'entropy = 0.811\\nsamples = 36\\nvalue = [9, 27]'),\n",
       " Text(42.67281355932204, 67.30285714285714, 'entropy = 0.156\\nsamples = 44\\nvalue = [1, 43]'),\n",
       " Text(42.30964067796611, 88.01142857142858, 'entropy = 0.0\\nsamples = 159\\nvalue = [0, 159]'),\n",
       " Text(32.62172033898305, 139.78285714285715, 'X[2] <= 0.011\\nentropy = 0.131\\nsamples = 274\\nvalue = [5, 269]'),\n",
       " Text(32.258547457627124, 129.42857142857144, 'entropy = 0.0\\nsamples = 226\\nvalue = [0, 226]'),\n",
       " Text(32.98489322033898, 129.42857142857144, 'entropy = 0.482\\nsamples = 48\\nvalue = [5, 43]'),\n",
       " Text(61.21165423728814, 150.13714285714286, 'X[10] <= 1.361\\nentropy = 0.305\\nsamples = 3936\\nvalue = [214, 3722]'),\n",
       " Text(55.78108474576272, 139.78285714285715, 'X[5] <= 1.096\\nentropy = 0.341\\nsamples = 3135\\nvalue = [199, 2936]'),\n",
       " Text(50.957694915254244, 129.42857142857144, 'X[1] <= -0.453\\nentropy = 0.296\\nsamples = 2501\\nvalue = [131, 2370]'),\n",
       " Text(47.66644067796611, 119.07428571428571, 'X[11] <= -0.874\\nentropy = 0.396\\nsamples = 919\\nvalue = [72, 847]'),\n",
       " Text(45.75978305084746, 108.72, 'X[5] <= 0.467\\nentropy = 0.253\\nsamples = 566\\nvalue = [24, 542]'),\n",
       " Text(44.851850847457634, 98.36571428571429, 'X[6] <= 1.415\\nentropy = 0.177\\nsamples = 450\\nvalue = [12, 438]'),\n",
       " Text(44.12550508474577, 88.01142857142858, 'X[10] <= 0.73\\nentropy = 0.105\\nsamples = 364\\nvalue = [5, 359]'),\n",
       " Text(43.76233220338983, 77.65714285714284, 'X[3] <= 0.006\\nentropy = 0.193\\nsamples = 168\\nvalue = [5, 163]'),\n",
       " Text(43.3991593220339, 67.30285714285714, 'X[5] <= -1.553\\nentropy = 0.065\\nsamples = 130\\nvalue = [1, 129]'),\n",
       " Text(43.035986440677966, 56.94857142857143, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(43.76233220338983, 56.94857142857143, 'entropy = 0.0\\nsamples = 105\\nvalue = [0, 105]'),\n",
       " Text(44.12550508474577, 67.30285714285714, 'entropy = 0.485\\nsamples = 38\\nvalue = [4, 34]'),\n",
       " Text(44.4886779661017, 77.65714285714284, 'entropy = 0.0\\nsamples = 196\\nvalue = [0, 196]'),\n",
       " Text(45.57819661016949, 88.01142857142858, 'X[9] <= -0.877\\nentropy = 0.407\\nsamples = 86\\nvalue = [7, 79]'),\n",
       " Text(45.21502372881356, 77.65714285714284, 'entropy = 0.709\\nsamples = 31\\nvalue = [6, 25]'),\n",
       " Text(45.94136949152543, 77.65714285714284, 'X[5] <= -0.505\\nentropy = 0.131\\nsamples = 55\\nvalue = [1, 54]'),\n",
       " Text(45.57819661016949, 67.30285714285714, 'entropy = 0.0\\nsamples = 30\\nvalue = [0, 30]'),\n",
       " Text(46.30454237288136, 67.30285714285714, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(46.667715254237294, 98.36571428571429, 'X[2] <= -0.055\\nentropy = 0.48\\nsamples = 116\\nvalue = [12, 104]'),\n",
       " Text(46.30454237288136, 88.01142857142858, 'entropy = 0.0\\nsamples = 36\\nvalue = [0, 36]'),\n",
       " Text(47.03088813559322, 88.01142857142858, 'X[2] <= 0.042\\nentropy = 0.61\\nsamples = 80\\nvalue = [12, 68]'),\n",
       " Text(46.667715254237294, 77.65714285714284, 'entropy = 0.918\\nsamples = 30\\nvalue = [10, 20]'),\n",
       " Text(47.39406101694916, 77.65714285714284, 'X[5] <= 0.76\\nentropy = 0.242\\nsamples = 50\\nvalue = [2, 48]'),\n",
       " Text(47.03088813559322, 67.30285714285714, 'entropy = 0.402\\nsamples = 25\\nvalue = [2, 23]'),\n",
       " Text(47.75723389830509, 67.30285714285714, 'entropy = 0.0\\nsamples = 25\\nvalue = [0, 25]'),\n",
       " Text(49.57309830508475, 108.72, 'X[1] <= -0.467\\nentropy = 0.574\\nsamples = 353\\nvalue = [48, 305]'),\n",
       " Text(49.20992542372882, 98.36571428571429, 'entropy = 0.974\\nsamples = 42\\nvalue = [17, 25]'),\n",
       " Text(49.936271186440685, 98.36571428571429, 'X[11] <= 1.031\\nentropy = 0.468\\nsamples = 311\\nvalue = [31, 280]'),\n",
       " Text(49.57309830508475, 88.01142857142858, 'X[13] <= -0.523\\nentropy = 0.367\\nsamples = 270\\nvalue = [19, 251]'),\n",
       " Text(49.20992542372882, 77.65714285714284, 'X[2] <= -0.061\\nentropy = 0.416\\nsamples = 226\\nvalue = [19, 207]'),\n",
       " Text(48.483579661016954, 67.30285714285714, 'X[10] <= 0.73\\nentropy = 0.206\\nsamples = 93\\nvalue = [3, 90]'),\n",
       " Text(48.12040677966102, 56.94857142857143, 'entropy = 0.348\\nsamples = 46\\nvalue = [3, 43]'),\n",
       " Text(48.84675254237288, 56.94857142857143, 'entropy = 0.0\\nsamples = 47\\nvalue = [0, 47]'),\n",
       " Text(49.936271186440685, 67.30285714285714, 'X[9] <= -0.266\\nentropy = 0.53\\nsamples = 133\\nvalue = [16, 117]'),\n",
       " Text(49.57309830508475, 56.94857142857143, 'entropy = 0.773\\nsamples = 44\\nvalue = [10, 34]'),\n",
       " Text(50.299444067796614, 56.94857142857143, 'X[13] <= -0.528\\nentropy = 0.356\\nsamples = 89\\nvalue = [6, 83]'),\n",
       " Text(49.936271186440685, 46.59428571428572, 'entropy = 0.536\\nsamples = 49\\nvalue = [6, 43]'),\n",
       " Text(50.66261694915254, 46.59428571428572, 'entropy = 0.0\\nsamples = 40\\nvalue = [0, 40]'),\n",
       " Text(49.936271186440685, 77.65714285714284, 'entropy = 0.0\\nsamples = 44\\nvalue = [0, 44]'),\n",
       " Text(50.299444067796614, 88.01142857142858, 'entropy = 0.872\\nsamples = 41\\nvalue = [12, 29]'),\n",
       " Text(54.24894915254238, 119.07428571428571, 'X[2] <= -0.022\\nentropy = 0.23\\nsamples = 1582\\nvalue = [59, 1523]'),\n",
       " Text(53.20482711864407, 108.72, 'X[4] <= 1.138\\nentropy = 0.156\\nsamples = 882\\nvalue = [20, 862]'),\n",
       " Text(52.84165423728814, 98.36571428571429, 'X[1] <= -0.318\\nentropy = 0.195\\nsamples = 662\\nvalue = [20, 642]'),\n",
       " Text(52.47848135593221, 88.01142857142858, 'X[13] <= -0.525\\nentropy = 0.169\\nsamples = 637\\nvalue = [16, 621]'),\n",
       " Text(51.752135593220345, 77.65714285714284, 'X[11] <= 0.6\\nentropy = 0.126\\nsamples = 521\\nvalue = [9, 512]'),\n",
       " Text(51.38896271186441, 67.30285714285714, 'X[4] <= -1.356\\nentropy = 0.083\\nsamples = 487\\nvalue = [5, 482]'),\n",
       " Text(51.02578983050848, 56.94857142857143, 'entropy = 0.348\\nsamples = 46\\nvalue = [3, 43]'),\n",
       " Text(51.752135593220345, 56.94857142857143, 'X[6] <= -1.487\\nentropy = 0.042\\nsamples = 441\\nvalue = [2, 439]'),\n",
       " Text(51.38896271186441, 46.59428571428572, 'X[2] <= -0.092\\nentropy = 0.128\\nsamples = 113\\nvalue = [2, 111]'),\n",
       " Text(51.02578983050848, 36.24000000000001, 'entropy = 0.0\\nsamples = 87\\nvalue = [0, 87]'),\n",
       " Text(51.752135593220345, 36.24000000000001, 'entropy = 0.391\\nsamples = 26\\nvalue = [2, 24]'),\n",
       " Text(52.115308474576274, 46.59428571428572, 'entropy = 0.0\\nsamples = 328\\nvalue = [0, 328]'),\n",
       " Text(52.115308474576274, 67.30285714285714, 'entropy = 0.523\\nsamples = 34\\nvalue = [4, 30]'),\n",
       " Text(53.20482711864407, 77.65714285714284, 'X[12] <= 1.213\\nentropy = 0.329\\nsamples = 116\\nvalue = [7, 109]'),\n",
       " Text(52.84165423728814, 67.30285714285714, 'X[11] <= -0.382\\nentropy = 0.493\\nsamples = 65\\nvalue = [7, 58]'),\n",
       " Text(52.47848135593221, 56.94857142857143, 'entropy = 0.629\\nsamples = 38\\nvalue = [6, 32]'),\n",
       " Text(53.20482711864407, 56.94857142857143, 'entropy = 0.229\\nsamples = 27\\nvalue = [1, 26]'),\n",
       " Text(53.568000000000005, 67.30285714285714, 'entropy = 0.0\\nsamples = 51\\nvalue = [0, 51]'),\n",
       " Text(53.20482711864407, 88.01142857142858, 'entropy = 0.634\\nsamples = 25\\nvalue = [4, 21]'),\n",
       " Text(53.568000000000005, 98.36571428571429, 'entropy = 0.0\\nsamples = 220\\nvalue = [0, 220]'),\n",
       " Text(55.293071186440685, 108.72, 'X[5] <= -1.456\\nentropy = 0.31\\nsamples = 700\\nvalue = [39, 661]'),\n",
       " Text(54.56672542372882, 98.36571428571429, 'X[3] <= -0.007\\nentropy = 0.052\\nsamples = 169\\nvalue = [1, 168]'),\n",
       " Text(54.20355254237288, 88.01142857142858, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(54.92989830508475, 88.01142857142858, 'entropy = 0.0\\nsamples = 144\\nvalue = [0, 144]'),\n",
       " Text(56.01941694915255, 98.36571428571429, 'X[15] <= 0.725\\nentropy = 0.372\\nsamples = 531\\nvalue = [38, 493]'),\n",
       " Text(55.656244067796614, 88.01142857142858, 'X[13] <= -0.534\\nentropy = 0.41\\nsamples = 462\\nvalue = [38, 424]'),\n",
       " Text(54.6575186440678, 77.65714285714284, 'X[1] <= -0.346\\nentropy = 0.626\\nsamples = 115\\nvalue = [18, 97]'),\n",
       " Text(54.29434576271187, 67.30285714285714, 'X[1] <= -0.395\\nentropy = 0.722\\nsamples = 80\\nvalue = [16, 64]'),\n",
       " Text(53.931172881355934, 56.94857142857143, 'entropy = 0.482\\nsamples = 48\\nvalue = [5, 43]'),\n",
       " Text(54.6575186440678, 56.94857142857143, 'entropy = 0.928\\nsamples = 32\\nvalue = [11, 21]'),\n",
       " Text(55.020691525423736, 67.30285714285714, 'entropy = 0.316\\nsamples = 35\\nvalue = [2, 33]'),\n",
       " Text(56.65496949152543, 77.65714285714284, 'X[1] <= -0.428\\nentropy = 0.318\\nsamples = 347\\nvalue = [20, 327]'),\n",
       " Text(55.747037288135594, 67.30285714285714, 'X[11] <= 1.122\\nentropy = 0.51\\nsamples = 106\\nvalue = [12, 94]'),\n",
       " Text(55.383864406779665, 56.94857142857143, 'X[6] <= -0.12\\nentropy = 0.645\\nsamples = 73\\nvalue = [12, 61]'),\n",
       " Text(55.020691525423736, 46.59428571428572, 'entropy = 0.0\\nsamples = 32\\nvalue = [0, 32]'),\n",
       " Text(55.747037288135594, 46.59428571428572, 'entropy = 0.872\\nsamples = 41\\nvalue = [12, 29]'),\n",
       " Text(56.11021016949153, 56.94857142857143, 'entropy = 0.0\\nsamples = 33\\nvalue = [0, 33]'),\n",
       " Text(57.56290169491526, 67.30285714285714, 'X[6] <= 0.138\\nentropy = 0.21\\nsamples = 241\\nvalue = [8, 233]'),\n",
       " Text(56.836555932203396, 56.94857142857143, 'X[10] <= 0.73\\nentropy = 0.346\\nsamples = 108\\nvalue = [7, 101]'),\n",
       " Text(56.47338305084746, 46.59428571428572, 'X[7] <= 0.297\\nentropy = 0.52\\nsamples = 60\\nvalue = [7, 53]'),\n",
       " Text(56.11021016949153, 36.24000000000001, 'entropy = 0.795\\nsamples = 25\\nvalue = [6, 19]'),\n",
       " Text(56.836555932203396, 36.24000000000001, 'entropy = 0.187\\nsamples = 35\\nvalue = [1, 34]'),\n",
       " Text(57.199728813559325, 46.59428571428572, 'entropy = 0.0\\nsamples = 48\\nvalue = [0, 48]'),\n",
       " Text(58.28924745762712, 56.94857142857143, 'X[7] <= -0.768\\nentropy = 0.064\\nsamples = 133\\nvalue = [1, 132]'),\n",
       " Text(57.92607457627119, 46.59428571428572, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(58.652420338983056, 46.59428571428572, 'entropy = 0.0\\nsamples = 108\\nvalue = [0, 108]'),\n",
       " Text(56.38258983050848, 88.01142857142858, 'entropy = 0.0\\nsamples = 69\\nvalue = [0, 69]'),\n",
       " Text(60.604474576271194, 129.42857142857144, 'X[9] <= 1.77\\nentropy = 0.492\\nsamples = 634\\nvalue = [68, 566]'),\n",
       " Text(60.24130169491526, 119.07428571428571, 'X[9] <= -1.243\\nentropy = 0.518\\nsamples = 585\\nvalue = [68, 517]'),\n",
       " Text(59.87812881355933, 108.72, 'entropy = 0.0\\nsamples = 32\\nvalue = [0, 32]'),\n",
       " Text(60.604474576271194, 108.72, 'X[2] <= 0.157\\nentropy = 0.538\\nsamples = 553\\nvalue = [68, 485]'),\n",
       " Text(60.24130169491526, 98.36571428571429, 'X[6] <= -1.407\\nentropy = 0.557\\nsamples = 524\\nvalue = [68, 456]'),\n",
       " Text(58.28924745762712, 88.01142857142858, 'X[5] <= 1.588\\nentropy = 0.35\\nsamples = 137\\nvalue = [9, 128]'),\n",
       " Text(57.92607457627119, 77.65714285714284, 'entropy = 0.0\\nsamples = 55\\nvalue = [0, 55]'),\n",
       " Text(58.652420338983056, 77.65714285714284, 'X[13] <= -0.523\\nentropy = 0.499\\nsamples = 82\\nvalue = [9, 73]'),\n",
       " Text(58.28924745762712, 67.30285714285714, 'entropy = 0.705\\nsamples = 47\\nvalue = [9, 38]'),\n",
       " Text(59.015593220338985, 67.30285714285714, 'entropy = 0.0\\nsamples = 35\\nvalue = [0, 35]'),\n",
       " Text(62.193355932203396, 88.01142857142858, 'X[18] <= 0.514\\nentropy = 0.616\\nsamples = 387\\nvalue = [59, 328]'),\n",
       " Text(60.468284745762716, 77.65714285714284, 'X[1] <= -0.456\\nentropy = 0.467\\nsamples = 181\\nvalue = [18, 163]'),\n",
       " Text(59.74193898305085, 67.30285714285714, 'X[12] <= 1.184\\nentropy = 0.752\\nsamples = 65\\nvalue = [14, 51]'),\n",
       " Text(59.37876610169492, 56.94857142857143, 'entropy = 0.963\\nsamples = 31\\nvalue = [12, 19]'),\n",
       " Text(60.10511186440679, 56.94857142857143, 'entropy = 0.323\\nsamples = 34\\nvalue = [2, 32]'),\n",
       " Text(61.19463050847458, 67.30285714285714, 'X[1] <= -0.415\\nentropy = 0.216\\nsamples = 116\\nvalue = [4, 112]'),\n",
       " Text(60.831457627118645, 56.94857142857143, 'entropy = 0.0\\nsamples = 91\\nvalue = [0, 91]'),\n",
       " Text(61.55780338983051, 56.94857142857143, 'entropy = 0.634\\nsamples = 25\\nvalue = [4, 21]'),\n",
       " Text(63.918427118644075, 77.65714285714284, 'X[2] <= -0.007\\nentropy = 0.72\\nsamples = 206\\nvalue = [41, 165]'),\n",
       " Text(63.01049491525424, 67.30285714285714, 'X[9] <= -0.206\\nentropy = 0.814\\nsamples = 131\\nvalue = [33, 98]'),\n",
       " Text(62.284149152542376, 56.94857142857143, 'X[4] <= 0.074\\nentropy = 0.939\\nsamples = 59\\nvalue = [21, 38]'),\n",
       " Text(61.92097627118645, 46.59428571428572, 'entropy = 1.0\\nsamples = 28\\nvalue = [14, 14]'),\n",
       " Text(62.64732203389831, 46.59428571428572, 'entropy = 0.771\\nsamples = 31\\nvalue = [7, 24]'),\n",
       " Text(63.73684067796611, 56.94857142857143, 'X[13] <= -0.531\\nentropy = 0.65\\nsamples = 72\\nvalue = [12, 60]'),\n",
       " Text(63.37366779661017, 46.59428571428572, 'entropy = 0.906\\nsamples = 28\\nvalue = [9, 19]'),\n",
       " Text(64.10001355932204, 46.59428571428572, 'entropy = 0.359\\nsamples = 44\\nvalue = [3, 41]'),\n",
       " Text(64.82635932203391, 67.30285714285714, 'X[2] <= 0.026\\nentropy = 0.49\\nsamples = 75\\nvalue = [8, 67]'),\n",
       " Text(64.46318644067797, 56.94857142857143, 'entropy = 0.191\\nsamples = 34\\nvalue = [1, 33]'),\n",
       " Text(65.18953220338983, 56.94857142857143, 'entropy = 0.659\\nsamples = 41\\nvalue = [7, 34]'),\n",
       " Text(60.96764745762712, 98.36571428571429, 'entropy = 0.0\\nsamples = 29\\nvalue = [0, 29]'),\n",
       " Text(60.96764745762712, 119.07428571428571, 'entropy = 0.0\\nsamples = 49\\nvalue = [0, 49]'),\n",
       " Text(66.64222372881356, 139.78285714285715, 'X[4] <= -1.235\\nentropy = 0.134\\nsamples = 801\\nvalue = [15, 786]'),\n",
       " Text(65.9158779661017, 129.42857142857144, 'X[3] <= -0.004\\nentropy = 0.323\\nsamples = 85\\nvalue = [5, 80]'),\n",
       " Text(65.55270508474577, 119.07428571428571, 'entropy = 0.0\\nsamples = 56\\nvalue = [0, 56]'),\n",
       " Text(66.27905084745763, 119.07428571428571, 'entropy = 0.663\\nsamples = 29\\nvalue = [5, 24]'),\n",
       " Text(67.36856949152543, 129.42857142857144, 'X[3] <= -0.002\\nentropy = 0.106\\nsamples = 716\\nvalue = [10, 706]'),\n",
       " Text(67.0053966101695, 119.07428571428571, 'X[12] <= 1.813\\nentropy = 0.14\\nsamples = 505\\nvalue = [10, 495]'),\n",
       " Text(66.64222372881356, 108.72, 'X[5] <= 0.916\\nentropy = 0.111\\nsamples = 475\\nvalue = [7, 468]'),\n",
       " Text(65.9158779661017, 98.36571428571429, 'X[13] <= -0.534\\nentropy = 0.067\\nsamples = 378\\nvalue = [3, 375]'),\n",
       " Text(65.55270508474577, 88.01142857142858, 'X[6] <= -0.817\\nentropy = 0.186\\nsamples = 106\\nvalue = [3, 103]'),\n",
       " Text(65.18953220338983, 77.65714285714284, 'entropy = 0.0\\nsamples = 54\\nvalue = [0, 54]'),\n",
       " Text(65.9158779661017, 77.65714285714284, 'X[4] <= 0.436\\nentropy = 0.318\\nsamples = 52\\nvalue = [3, 49]'),\n",
       " Text(65.55270508474577, 67.30285714285714, 'entropy = 0.402\\nsamples = 25\\nvalue = [2, 23]'),\n",
       " Text(66.27905084745763, 67.30285714285714, 'entropy = 0.229\\nsamples = 27\\nvalue = [1, 26]'),\n",
       " Text(66.27905084745763, 88.01142857142858, 'entropy = 0.0\\nsamples = 272\\nvalue = [0, 272]'),\n",
       " Text(67.36856949152543, 98.36571428571429, 'X[11] <= -0.555\\nentropy = 0.248\\nsamples = 97\\nvalue = [4, 93]'),\n",
       " Text(67.0053966101695, 88.01142857142858, 'entropy = 0.461\\nsamples = 41\\nvalue = [4, 37]'),\n",
       " Text(67.73174237288136, 88.01142857142858, 'entropy = 0.0\\nsamples = 56\\nvalue = [0, 56]'),\n",
       " Text(67.36856949152543, 108.72, 'entropy = 0.469\\nsamples = 30\\nvalue = [3, 27]'),\n",
       " Text(67.73174237288136, 119.07428571428571, 'entropy = 0.0\\nsamples = 211\\nvalue = [0, 211]'),\n",
       " Text(73.13393898305085, 160.49142857142857, 'X[11] <= -0.784\\nentropy = 0.739\\nsamples = 1743\\nvalue = [364, 1379]'),\n",
       " Text(70.63712542372882, 150.13714285714286, 'X[8] <= 1.094\\nentropy = 0.454\\nsamples = 535\\nvalue = [51, 484]'),\n",
       " Text(70.27395254237288, 139.78285714285715, 'X[7] <= -1.017\\nentropy = 0.516\\nsamples = 442\\nvalue = [51, 391]'),\n",
       " Text(68.82126101694915, 129.42857142857144, 'X[7] <= -1.195\\nentropy = 0.232\\nsamples = 238\\nvalue = [9, 229]'),\n",
       " Text(68.45808813559323, 119.07428571428571, 'X[11] <= -1.319\\nentropy = 0.297\\nsamples = 171\\nvalue = [9, 162]'),\n",
       " Text(68.09491525423729, 108.72, 'entropy = 0.634\\nsamples = 25\\nvalue = [4, 21]'),\n",
       " Text(68.82126101694915, 108.72, 'X[13] <= -0.528\\nentropy = 0.215\\nsamples = 146\\nvalue = [5, 141]'),\n",
       " Text(68.45808813559323, 98.36571428571429, 'entropy = 0.469\\nsamples = 40\\nvalue = [4, 36]'),\n",
       " Text(69.18443389830509, 98.36571428571429, 'X[2] <= -0.022\\nentropy = 0.077\\nsamples = 106\\nvalue = [1, 105]'),\n",
       " Text(68.82126101694915, 88.01142857142858, 'entropy = 0.0\\nsamples = 81\\nvalue = [0, 81]'),\n",
       " Text(69.54760677966102, 88.01142857142858, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(69.18443389830509, 119.07428571428571, 'entropy = 0.0\\nsamples = 67\\nvalue = [0, 67]'),\n",
       " Text(71.72664406779661, 129.42857142857144, 'X[5] <= 0.91\\nentropy = 0.734\\nsamples = 204\\nvalue = [42, 162]'),\n",
       " Text(71.36347118644068, 119.07428571428571, 'X[1] <= -0.405\\nentropy = 0.809\\nsamples = 161\\nvalue = [40, 121]'),\n",
       " Text(71.00029830508475, 108.72, 'X[3] <= -0.004\\nentropy = 0.89\\nsamples = 114\\nvalue = [35, 79]'),\n",
       " Text(70.63712542372882, 98.36571428571429, 'X[1] <= -0.434\\nentropy = 0.966\\nsamples = 74\\nvalue = [29, 45]'),\n",
       " Text(70.27395254237288, 88.01142857142858, 'entropy = 0.879\\nsamples = 47\\nvalue = [14, 33]'),\n",
       " Text(71.00029830508475, 88.01142857142858, 'entropy = 0.991\\nsamples = 27\\nvalue = [15, 12]'),\n",
       " Text(71.36347118644068, 98.36571428571429, 'entropy = 0.61\\nsamples = 40\\nvalue = [6, 34]'),\n",
       " Text(71.72664406779661, 108.72, 'entropy = 0.489\\nsamples = 47\\nvalue = [5, 42]'),\n",
       " Text(72.08981694915255, 119.07428571428571, 'entropy = 0.271\\nsamples = 43\\nvalue = [2, 41]'),\n",
       " Text(71.00029830508475, 139.78285714285715, 'entropy = 0.0\\nsamples = 93\\nvalue = [0, 93]'),\n",
       " Text(75.63075254237289, 150.13714285714286, 'X[10] <= 1.046\\nentropy = 0.825\\nsamples = 1208\\nvalue = [313, 895]'),\n",
       " Text(74.45044067796611, 139.78285714285715, 'X[0] <= 1.073\\nentropy = 0.879\\nsamples = 985\\nvalue = [294, 691]'),\n",
       " Text(74.08726779661018, 129.42857142857144, 'X[15] <= 0.725\\nentropy = 0.894\\nsamples = 945\\nvalue = [294, 651]'),\n",
       " Text(73.17933559322034, 119.07428571428571, 'X[4] <= -1.794\\nentropy = 0.856\\nsamples = 835\\nvalue = [234, 601]'),\n",
       " Text(72.45298983050849, 108.72, 'X[4] <= -1.848\\nentropy = 0.96\\nsamples = 68\\nvalue = [42, 26]'),\n",
       " Text(72.08981694915255, 98.36571428571429, 'entropy = 0.988\\nsamples = 39\\nvalue = [17, 22]'),\n",
       " Text(72.81616271186441, 98.36571428571429, 'entropy = 0.579\\nsamples = 29\\nvalue = [25, 4]'),\n",
       " Text(73.9056813559322, 108.72, 'X[1] <= -0.464\\nentropy = 0.812\\nsamples = 767\\nvalue = [192, 575]'),\n",
       " Text(73.54250847457628, 98.36571428571429, 'entropy = 0.918\\nsamples = 36\\nvalue = [24, 12]'),\n",
       " Text(74.26885423728814, 98.36571428571429, 'X[12] <= 0.546\\nentropy = 0.778\\nsamples = 731\\nvalue = [168, 563]'),\n",
       " Text(72.54378305084747, 88.01142857142858, 'X[3] <= -0.011\\nentropy = 0.859\\nsamples = 495\\nvalue = [140, 355]'),\n",
       " Text(72.18061016949153, 77.65714285714284, 'entropy = 0.855\\nsamples = 25\\nvalue = [18, 7]'),\n",
       " Text(72.9069559322034, 77.65714285714284, 'X[1] <= -0.386\\nentropy = 0.826\\nsamples = 470\\nvalue = [122, 348]'),\n",
       " Text(71.63585084745763, 67.30285714285714, 'X[2] <= 0.041\\nentropy = 0.673\\nsamples = 249\\nvalue = [44, 205]'),\n",
       " Text(70.7279186440678, 56.94857142857143, 'X[0] <= -0.149\\nentropy = 0.75\\nsamples = 191\\nvalue = [41, 150]'),\n",
       " Text(70.00157288135594, 46.59428571428572, 'X[5] <= 0.34\\nentropy = 0.946\\nsamples = 55\\nvalue = [20, 35]'),\n",
       " Text(69.6384, 36.24000000000001, 'entropy = 0.992\\nsamples = 29\\nvalue = [16, 13]'),\n",
       " Text(70.36474576271188, 36.24000000000001, 'entropy = 0.619\\nsamples = 26\\nvalue = [4, 22]'),\n",
       " Text(71.45426440677967, 46.59428571428572, 'X[2] <= -0.016\\nentropy = 0.621\\nsamples = 136\\nvalue = [21, 115]'),\n",
       " Text(71.09109152542374, 36.24000000000001, 'X[1] <= -0.451\\nentropy = 0.383\\nsamples = 107\\nvalue = [8, 99]'),\n",
       " Text(70.7279186440678, 25.8857142857143, 'entropy = 0.712\\nsamples = 41\\nvalue = [8, 33]'),\n",
       " Text(71.45426440677967, 25.8857142857143, 'entropy = 0.0\\nsamples = 66\\nvalue = [0, 66]'),\n",
       " Text(71.8174372881356, 36.24000000000001, 'entropy = 0.992\\nsamples = 29\\nvalue = [13, 16]'),\n",
       " Text(72.54378305084747, 56.94857142857143, 'X[8] <= 0.186\\nentropy = 0.294\\nsamples = 58\\nvalue = [3, 55]'),\n",
       " Text(72.18061016949153, 46.59428571428572, 'entropy = 0.529\\nsamples = 25\\nvalue = [3, 22]'),\n",
       " Text(72.9069559322034, 46.59428571428572, 'entropy = 0.0\\nsamples = 33\\nvalue = [0, 33]'),\n",
       " Text(74.17806101694916, 67.30285714285714, 'X[12] <= -0.659\\nentropy = 0.937\\nsamples = 221\\nvalue = [78, 143]'),\n",
       " Text(73.81488813559322, 56.94857142857143, 'entropy = 0.303\\nsamples = 37\\nvalue = [2, 35]'),\n",
       " Text(74.5412338983051, 56.94857142857143, 'X[3] <= -0.006\\nentropy = 0.978\\nsamples = 184\\nvalue = [76, 108]'),\n",
       " Text(73.63330169491526, 46.59428571428572, 'X[0] <= -0.02\\nentropy = 0.898\\nsamples = 124\\nvalue = [39, 85]'),\n",
       " Text(72.9069559322034, 36.24000000000001, 'X[10] <= -0.532\\nentropy = 0.631\\nsamples = 63\\nvalue = [10, 53]'),\n",
       " Text(72.54378305084747, 25.8857142857143, 'entropy = 0.94\\nsamples = 28\\nvalue = [10, 18]'),\n",
       " Text(73.27012881355932, 25.8857142857143, 'entropy = 0.0\\nsamples = 35\\nvalue = [0, 35]'),\n",
       " Text(74.35964745762712, 36.24000000000001, 'X[9] <= 0.905\\nentropy = 0.998\\nsamples = 61\\nvalue = [29, 32]'),\n",
       " Text(73.9964745762712, 25.8857142857143, 'entropy = 0.904\\nsamples = 25\\nvalue = [17, 8]'),\n",
       " Text(74.72282033898306, 25.8857142857143, 'entropy = 0.918\\nsamples = 36\\nvalue = [12, 24]'),\n",
       " Text(75.44916610169493, 46.59428571428572, 'X[1] <= -0.369\\nentropy = 0.96\\nsamples = 60\\nvalue = [37, 23]'),\n",
       " Text(75.08599322033899, 36.24000000000001, 'entropy = 0.353\\nsamples = 30\\nvalue = [28, 2]'),\n",
       " Text(75.81233898305085, 36.24000000000001, 'entropy = 0.881\\nsamples = 30\\nvalue = [9, 21]'),\n",
       " Text(75.99392542372883, 88.01142857142858, 'X[1] <= -0.44\\nentropy = 0.525\\nsamples = 236\\nvalue = [28, 208]'),\n",
       " Text(75.26757966101695, 77.65714285714284, 'X[3] <= -0.008\\nentropy = 0.729\\nsamples = 108\\nvalue = [22, 86]'),\n",
       " Text(74.90440677966102, 67.30285714285714, 'entropy = 0.982\\nsamples = 38\\nvalue = [16, 22]'),\n",
       " Text(75.63075254237289, 67.30285714285714, 'X[10] <= -0.216\\nentropy = 0.422\\nsamples = 70\\nvalue = [6, 64]'),\n",
       " Text(75.26757966101695, 56.94857142857143, 'entropy = 0.592\\nsamples = 42\\nvalue = [6, 36]'),\n",
       " Text(75.99392542372883, 56.94857142857143, 'entropy = 0.0\\nsamples = 28\\nvalue = [0, 28]'),\n",
       " Text(76.72027118644068, 77.65714285714284, 'X[10] <= -0.216\\nentropy = 0.273\\nsamples = 128\\nvalue = [6, 122]'),\n",
       " Text(76.35709830508475, 67.30285714285714, 'entropy = 0.0\\nsamples = 59\\nvalue = [0, 59]'),\n",
       " Text(77.08344406779662, 67.30285714285714, 'X[11] <= -0.344\\nentropy = 0.426\\nsamples = 69\\nvalue = [6, 63]'),\n",
       " Text(76.72027118644068, 56.94857142857143, 'entropy = 0.191\\nsamples = 34\\nvalue = [1, 33]'),\n",
       " Text(77.44661694915254, 56.94857142857143, 'entropy = 0.592\\nsamples = 35\\nvalue = [5, 30]'),\n",
       " Text(74.99520000000001, 119.07428571428571, 'X[1] <= -0.426\\nentropy = 0.994\\nsamples = 110\\nvalue = [60, 50]'),\n",
       " Text(74.63202711864407, 108.72, 'entropy = 0.398\\nsamples = 38\\nvalue = [35, 3]'),\n",
       " Text(75.35837288135593, 108.72, 'X[9] <= 0.189\\nentropy = 0.932\\nsamples = 72\\nvalue = [25, 47]'),\n",
       " Text(74.99520000000001, 98.36571428571429, 'entropy = 0.826\\nsamples = 27\\nvalue = [20, 7]'),\n",
       " Text(75.72154576271187, 98.36571428571429, 'entropy = 0.503\\nsamples = 45\\nvalue = [5, 40]'),\n",
       " Text(74.81361355932204, 129.42857142857144, 'entropy = 0.0\\nsamples = 40\\nvalue = [0, 40]'),\n",
       " Text(76.81106440677966, 139.78285714285715, 'X[8] <= -0.605\\nentropy = 0.42\\nsamples = 223\\nvalue = [19, 204]'),\n",
       " Text(76.0847186440678, 129.42857142857144, 'X[5] <= -0.001\\nentropy = 0.684\\nsamples = 99\\nvalue = [18, 81]'),\n",
       " Text(75.72154576271187, 119.07428571428571, 'entropy = 0.0\\nsamples = 30\\nvalue = [0, 30]'),\n",
       " Text(76.44789152542373, 119.07428571428571, 'X[2] <= -0.025\\nentropy = 0.828\\nsamples = 69\\nvalue = [18, 51]'),\n",
       " Text(76.0847186440678, 108.72, 'entropy = 0.449\\nsamples = 32\\nvalue = [3, 29]'),\n",
       " Text(76.81106440677966, 108.72, 'entropy = 0.974\\nsamples = 37\\nvalue = [15, 22]'),\n",
       " Text(77.53741016949154, 129.42857142857144, 'X[7] <= 1.264\\nentropy = 0.068\\nsamples = 124\\nvalue = [1, 123]'),\n",
       " Text(77.1742372881356, 119.07428571428571, 'entropy = 0.0\\nsamples = 99\\nvalue = [0, 99]'),\n",
       " Text(77.90058305084746, 119.07428571428571, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(77.53741016949154, 181.2, 'X[5] <= 0.822\\nentropy = 0.426\\nsamples = 184\\nvalue = [168, 16]'),\n",
       " Text(77.1742372881356, 170.84571428571428, 'X[3] <= -0.008\\nentropy = 0.262\\nsamples = 158\\nvalue = [151, 7]'),\n",
       " Text(76.81106440677966, 160.49142857142857, 'entropy = 0.0\\nsamples = 66\\nvalue = [66, 0]'),\n",
       " Text(77.53741016949154, 160.49142857142857, 'X[11] <= -1.188\\nentropy = 0.388\\nsamples = 92\\nvalue = [85, 7]'),\n",
       " Text(77.1742372881356, 150.13714285714286, 'entropy = 0.0\\nsamples = 29\\nvalue = [29, 0]'),\n",
       " Text(77.90058305084746, 150.13714285714286, 'X[11] <= -0.991\\nentropy = 0.503\\nsamples = 63\\nvalue = [56, 7]'),\n",
       " Text(77.53741016949154, 139.78285714285715, 'entropy = 0.689\\nsamples = 38\\nvalue = [31, 7]'),\n",
       " Text(78.2637559322034, 139.78285714285715, 'entropy = 0.0\\nsamples = 25\\nvalue = [25, 0]'),\n",
       " Text(77.90058305084746, 170.84571428571428, 'entropy = 0.931\\nsamples = 26\\nvalue = [17, 9]'),\n",
       " Text(104.12670127118645, 191.5542857142857, 'X[5] <= 0.427\\nentropy = 0.165\\nsamples = 19434\\nvalue = [472, 18962]'),\n",
       " Text(96.66853474576271, 181.2, 'X[0] <= 0.108\\nentropy = 0.112\\nsamples = 17154\\nvalue = [257, 16897]'),\n",
       " Text(91.10390338983052, 170.84571428571428, 'X[3] <= -0.008\\nentropy = 0.09\\nsamples = 16810\\nvalue = [193, 16617]'),\n",
       " Text(84.2419220338983, 160.49142857142857, 'X[11] <= -1.121\\nentropy = 0.179\\nsamples = 5243\\nvalue = [141, 5102]'),\n",
       " Text(81.05564745762713, 150.13714285714286, 'X[11] <= -1.615\\nentropy = 0.038\\nsamples = 1754\\nvalue = [7, 1747]'),\n",
       " Text(80.6924745762712, 139.78285714285715, 'entropy = 0.706\\nsamples = 26\\nvalue = [5, 21]'),\n",
       " Text(81.41882033898305, 139.78285714285715, 'X[6] <= -0.43\\nentropy = 0.013\\nsamples = 1728\\nvalue = [2, 1726]'),\n",
       " Text(81.05564745762713, 129.42857142857144, 'entropy = 0.0\\nsamples = 1702\\nvalue = [0, 1702]'),\n",
       " Text(81.78199322033899, 129.42857142857144, 'entropy = 0.391\\nsamples = 26\\nvalue = [2, 24]'),\n",
       " Text(87.4281966101695, 150.13714285714286, 'X[1] <= 1.416\\nentropy = 0.235\\nsamples = 3489\\nvalue = [134, 3355]'),\n",
       " Text(85.42507118644069, 139.78285714285715, 'X[2] <= -0.117\\nentropy = 0.273\\nsamples = 2832\\nvalue = [133, 2699]'),\n",
       " Text(82.50833898305085, 129.42857142857144, 'X[9] <= -0.447\\nentropy = 0.352\\nsamples = 1720\\nvalue = [114, 1606]'),\n",
       " Text(80.85136271186441, 119.07428571428571, 'X[6] <= -0.932\\nentropy = 0.261\\nsamples = 1312\\nvalue = [58, 1254]'),\n",
       " Text(80.48818983050847, 108.72, 'X[7] <= 0.716\\nentropy = 0.301\\nsamples = 1083\\nvalue = [58, 1025]'),\n",
       " Text(78.80851525423729, 98.36571428571429, 'X[4] <= -0.941\\nentropy = 0.23\\nsamples = 938\\nvalue = [35, 903]'),\n",
       " Text(77.80978983050848, 88.01142857142858, 'X[7] <= -1.081\\nentropy = 0.042\\nsamples = 440\\nvalue = [2, 438]'),\n",
       " Text(77.44661694915254, 77.65714285714284, 'entropy = 0.402\\nsamples = 25\\nvalue = [2, 23]'),\n",
       " Text(78.17296271186441, 77.65714285714284, 'entropy = 0.0\\nsamples = 415\\nvalue = [0, 415]'),\n",
       " Text(79.8072406779661, 88.01142857142858, 'X[5] <= -0.705\\nentropy = 0.352\\nsamples = 498\\nvalue = [33, 465]'),\n",
       " Text(78.89930847457627, 77.65714285714284, 'X[11] <= -0.892\\nentropy = 0.738\\nsamples = 72\\nvalue = [15, 57]'),\n",
       " Text(78.53613559322035, 67.30285714285714, 'entropy = 0.926\\nsamples = 44\\nvalue = [15, 29]'),\n",
       " Text(79.26248135593221, 67.30285714285714, 'entropy = 0.0\\nsamples = 28\\nvalue = [0, 28]'),\n",
       " Text(80.71517288135594, 77.65714285714284, 'X[1] <= -0.19\\nentropy = 0.253\\nsamples = 426\\nvalue = [18, 408]'),\n",
       " Text(79.98882711864407, 67.30285714285714, 'X[2] <= -0.148\\nentropy = 0.625\\nsamples = 64\\nvalue = [10, 54]'),\n",
       " Text(79.62565423728815, 56.94857142857143, 'entropy = 0.0\\nsamples = 27\\nvalue = [0, 27]'),\n",
       " Text(80.352, 56.94857142857143, 'entropy = 0.842\\nsamples = 37\\nvalue = [10, 27]'),\n",
       " Text(81.4415186440678, 67.30285714285714, 'X[11] <= -0.943\\nentropy = 0.153\\nsamples = 362\\nvalue = [8, 354]'),\n",
       " Text(81.07834576271188, 56.94857142857143, 'entropy = 0.0\\nsamples = 211\\nvalue = [0, 211]'),\n",
       " Text(81.80469152542373, 56.94857142857143, 'X[11] <= -0.907\\nentropy = 0.299\\nsamples = 151\\nvalue = [8, 143]'),\n",
       " Text(81.4415186440678, 46.59428571428572, 'entropy = 0.824\\nsamples = 31\\nvalue = [8, 23]'),\n",
       " Text(82.16786440677967, 46.59428571428572, 'entropy = 0.0\\nsamples = 120\\nvalue = [0, 120]'),\n",
       " Text(82.16786440677967, 98.36571428571429, 'X[4] <= -0.763\\nentropy = 0.631\\nsamples = 145\\nvalue = [23, 122]'),\n",
       " Text(81.80469152542373, 88.01142857142858, 'X[8] <= 0.47\\nentropy = 0.928\\nsamples = 67\\nvalue = [23, 44]'),\n",
       " Text(81.4415186440678, 77.65714285714284, 'entropy = 0.337\\nsamples = 32\\nvalue = [2, 30]'),\n",
       " Text(82.16786440677967, 77.65714285714284, 'entropy = 0.971\\nsamples = 35\\nvalue = [21, 14]'),\n",
       " Text(82.5310372881356, 88.01142857142858, 'entropy = 0.0\\nsamples = 78\\nvalue = [0, 78]'),\n",
       " Text(81.21453559322035, 108.72, 'entropy = 0.0\\nsamples = 229\\nvalue = [0, 229]'),\n",
       " Text(84.1653152542373, 119.07428571428571, 'X[12] <= -1.622\\nentropy = 0.577\\nsamples = 408\\nvalue = [56, 352]'),\n",
       " Text(83.25738305084747, 108.72, 'X[7] <= 0.431\\nentropy = 0.935\\nsamples = 57\\nvalue = [20, 37]'),\n",
       " Text(82.89421016949153, 98.36571428571429, 'entropy = 0.235\\nsamples = 26\\nvalue = [1, 25]'),\n",
       " Text(83.6205559322034, 98.36571428571429, 'entropy = 0.963\\nsamples = 31\\nvalue = [19, 12]'),\n",
       " Text(85.07324745762712, 108.72, 'X[1] <= -0.23\\nentropy = 0.477\\nsamples = 351\\nvalue = [36, 315]'),\n",
       " Text(84.34690169491526, 98.36571428571429, 'X[8] <= 0.016\\nentropy = 0.807\\nsamples = 93\\nvalue = [23, 70]'),\n",
       " Text(83.98372881355932, 88.01142857142858, 'entropy = 0.475\\nsamples = 49\\nvalue = [5, 44]'),\n",
       " Text(84.7100745762712, 88.01142857142858, 'entropy = 0.976\\nsamples = 44\\nvalue = [18, 26]'),\n",
       " Text(85.79959322033899, 98.36571428571429, 'X[0] <= -0.213\\nentropy = 0.288\\nsamples = 258\\nvalue = [13, 245]'),\n",
       " Text(85.43642033898305, 88.01142857142858, 'X[7] <= 0.439\\nentropy = 0.186\\nsamples = 212\\nvalue = [6, 206]'),\n",
       " Text(85.07324745762712, 77.65714285714284, 'X[6] <= -0.83\\nentropy = 0.378\\nsamples = 82\\nvalue = [6, 76]'),\n",
       " Text(84.7100745762712, 67.30285714285714, 'entropy = 0.601\\nsamples = 41\\nvalue = [6, 35]'),\n",
       " Text(85.43642033898305, 67.30285714285714, 'entropy = 0.0\\nsamples = 41\\nvalue = [0, 41]'),\n",
       " Text(85.79959322033899, 77.65714285714284, 'entropy = 0.0\\nsamples = 130\\nvalue = [0, 130]'),\n",
       " Text(86.16276610169493, 88.01142857142858, 'entropy = 0.615\\nsamples = 46\\nvalue = [7, 39]'),\n",
       " Text(88.34180338983052, 129.42857142857144, 'X[12] <= 0.132\\nentropy = 0.125\\nsamples = 1112\\nvalue = [19, 1093]'),\n",
       " Text(87.61545762711864, 119.07428571428571, 'X[13] <= 1.138\\nentropy = 0.081\\nsamples = 1001\\nvalue = [10, 991]'),\n",
       " Text(87.25228474576272, 108.72, 'X[6] <= -0.945\\nentropy = 0.115\\nsamples = 647\\nvalue = [10, 637]'),\n",
       " Text(86.88911186440679, 98.36571428571429, 'entropy = 0.0\\nsamples = 189\\nvalue = [0, 189]'),\n",
       " Text(87.61545762711864, 98.36571428571429, 'X[6] <= -0.615\\nentropy = 0.152\\nsamples = 458\\nvalue = [10, 448]'),\n",
       " Text(86.88911186440679, 88.01142857142858, 'X[7] <= 0.283\\nentropy = 0.308\\nsamples = 145\\nvalue = [8, 137]'),\n",
       " Text(86.52593898305085, 77.65714285714284, 'entropy = 0.722\\nsamples = 35\\nvalue = [7, 28]'),\n",
       " Text(87.25228474576272, 77.65714285714284, 'X[12] <= -1.477\\nentropy = 0.075\\nsamples = 110\\nvalue = [1, 109]'),\n",
       " Text(86.88911186440679, 67.30285714285714, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(87.61545762711864, 67.30285714285714, 'entropy = 0.0\\nsamples = 85\\nvalue = [0, 85]'),\n",
       " Text(88.34180338983052, 88.01142857142858, 'X[6] <= 0.299\\nentropy = 0.056\\nsamples = 313\\nvalue = [2, 311]'),\n",
       " Text(87.97863050847458, 77.65714285714284, 'entropy = 0.0\\nsamples = 264\\nvalue = [0, 264]'),\n",
       " Text(88.70497627118645, 77.65714285714284, 'entropy = 0.246\\nsamples = 49\\nvalue = [2, 47]'),\n",
       " Text(87.97863050847458, 108.72, 'entropy = 0.0\\nsamples = 354\\nvalue = [0, 354]'),\n",
       " Text(89.06814915254238, 119.07428571428571, 'X[9] <= 0.174\\nentropy = 0.406\\nsamples = 111\\nvalue = [9, 102]'),\n",
       " Text(88.70497627118645, 108.72, 'entropy = 0.713\\nsamples = 46\\nvalue = [9, 37]'),\n",
       " Text(89.43132203389831, 108.72, 'entropy = 0.0\\nsamples = 65\\nvalue = [0, 65]'),\n",
       " Text(89.43132203389831, 139.78285714285715, 'X[7] <= -0.925\\nentropy = 0.016\\nsamples = 657\\nvalue = [1, 656]'),\n",
       " Text(89.06814915254238, 129.42857142857144, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(89.79449491525425, 129.42857142857144, 'entropy = 0.0\\nsamples = 632\\nvalue = [0, 632]'),\n",
       " Text(97.96588474576272, 160.49142857142857, 'X[1] <= -0.061\\nentropy = 0.042\\nsamples = 11567\\nvalue = [52, 11515]'),\n",
       " Text(95.51446779661018, 150.13714285714286, 'X[12] <= 0.121\\nentropy = 0.084\\nsamples = 3822\\nvalue = [40, 3782]'),\n",
       " Text(94.3341559322034, 139.78285714285715, 'X[3] <= 0.001\\nentropy = 0.121\\nsamples = 2366\\nvalue = [39, 2327]'),\n",
       " Text(93.06305084745763, 129.42857142857144, 'X[9] <= 0.356\\nentropy = 0.089\\nsamples = 2295\\nvalue = [26, 2269]'),\n",
       " Text(91.6103593220339, 119.07428571428571, 'X[11] <= -0.437\\nentropy = 0.141\\nsamples = 1105\\nvalue = [22, 1083]'),\n",
       " Text(90.15766779661017, 108.72, 'X[9] <= -1.115\\nentropy = 0.075\\nsamples = 769\\nvalue = [7, 762]'),\n",
       " Text(89.43132203389831, 98.36571428571429, 'X[5] <= -0.471\\nentropy = 0.235\\nsamples = 130\\nvalue = [5, 125]'),\n",
       " Text(89.06814915254238, 88.01142857142858, 'entropy = 0.722\\nsamples = 25\\nvalue = [5, 20]'),\n",
       " Text(89.79449491525425, 88.01142857142858, 'entropy = 0.0\\nsamples = 105\\nvalue = [0, 105]'),\n",
       " Text(90.88401355932204, 98.36571428571429, 'X[8] <= 0.957\\nentropy = 0.031\\nsamples = 639\\nvalue = [2, 637]'),\n",
       " Text(90.5208406779661, 88.01142857142858, 'entropy = 0.0\\nsamples = 505\\nvalue = [0, 505]'),\n",
       " Text(91.24718644067798, 88.01142857142858, 'X[14] <= 0.157\\nentropy = 0.112\\nsamples = 134\\nvalue = [2, 132]'),\n",
       " Text(90.88401355932204, 77.65714285714284, 'entropy = 0.0\\nsamples = 100\\nvalue = [0, 100]'),\n",
       " Text(91.6103593220339, 77.65714285714284, 'entropy = 0.323\\nsamples = 34\\nvalue = [2, 32]'),\n",
       " Text(93.06305084745763, 108.72, 'X[2] <= -0.043\\nentropy = 0.263\\nsamples = 336\\nvalue = [15, 321]'),\n",
       " Text(92.33670508474577, 98.36571428571429, 'X[4] <= 0.159\\nentropy = 0.597\\nsamples = 76\\nvalue = [11, 65]'),\n",
       " Text(91.97353220338984, 88.01142857142858, 'entropy = 0.201\\nsamples = 32\\nvalue = [1, 31]'),\n",
       " Text(92.6998779661017, 88.01142857142858, 'entropy = 0.773\\nsamples = 44\\nvalue = [10, 34]'),\n",
       " Text(93.7893966101695, 98.36571428571429, 'X[2] <= 0.004\\nentropy = 0.115\\nsamples = 260\\nvalue = [4, 256]'),\n",
       " Text(93.42622372881357, 88.01142857142858, 'X[9] <= -0.266\\nentropy = 0.216\\nsamples = 116\\nvalue = [4, 112]'),\n",
       " Text(93.06305084745763, 77.65714285714284, 'entropy = 0.529\\nsamples = 25\\nvalue = [3, 22]'),\n",
       " Text(93.7893966101695, 77.65714285714284, 'X[5] <= -0.668\\nentropy = 0.087\\nsamples = 91\\nvalue = [1, 90]'),\n",
       " Text(93.42622372881357, 67.30285714285714, 'entropy = 0.0\\nsamples = 66\\nvalue = [0, 66]'),\n",
       " Text(94.15256949152543, 67.30285714285714, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(94.15256949152543, 88.01142857142858, 'entropy = 0.0\\nsamples = 144\\nvalue = [0, 144]'),\n",
       " Text(94.51574237288136, 119.07428571428571, 'X[0] <= -0.213\\nentropy = 0.032\\nsamples = 1190\\nvalue = [4, 1186]'),\n",
       " Text(94.15256949152543, 108.72, 'entropy = 0.0\\nsamples = 1018\\nvalue = [0, 1018]'),\n",
       " Text(94.8789152542373, 108.72, 'X[2] <= -0.034\\nentropy = 0.159\\nsamples = 172\\nvalue = [4, 168]'),\n",
       " Text(94.51574237288136, 98.36571428571429, 'entropy = 0.0\\nsamples = 85\\nvalue = [0, 85]'),\n",
       " Text(95.24208813559322, 98.36571428571429, 'X[4] <= 0.31\\nentropy = 0.269\\nsamples = 87\\nvalue = [4, 83]'),\n",
       " Text(94.8789152542373, 88.01142857142858, 'X[2] <= 0.027\\nentropy = 0.391\\nsamples = 52\\nvalue = [4, 48]'),\n",
       " Text(94.51574237288136, 77.65714285714284, 'entropy = 0.529\\nsamples = 25\\nvalue = [3, 22]'),\n",
       " Text(95.24208813559322, 77.65714285714284, 'entropy = 0.229\\nsamples = 27\\nvalue = [1, 26]'),\n",
       " Text(95.60526101694916, 88.01142857142858, 'entropy = 0.0\\nsamples = 35\\nvalue = [0, 35]'),\n",
       " Text(95.60526101694916, 129.42857142857144, 'X[4] <= 0.279\\nentropy = 0.687\\nsamples = 71\\nvalue = [13, 58]'),\n",
       " Text(95.24208813559322, 119.07428571428571, 'entropy = 0.985\\nsamples = 28\\nvalue = [12, 16]'),\n",
       " Text(95.9684338983051, 119.07428571428571, 'entropy = 0.159\\nsamples = 43\\nvalue = [1, 42]'),\n",
       " Text(96.69477966101695, 139.78285714285715, 'X[3] <= -0.008\\nentropy = 0.008\\nsamples = 1456\\nvalue = [1, 1455]'),\n",
       " Text(96.33160677966103, 129.42857142857144, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(97.05795254237289, 129.42857142857144, 'entropy = 0.0\\nsamples = 1431\\nvalue = [0, 1431]'),\n",
       " Text(100.41730169491527, 150.13714285714286, 'X[0] <= -0.213\\nentropy = 0.017\\nsamples = 7745\\nvalue = [12, 7733]'),\n",
       " Text(98.69223050847458, 139.78285714285715, 'X[8] <= -0.428\\nentropy = 0.008\\nsamples = 7095\\nvalue = [5, 7090]'),\n",
       " Text(97.78429830508475, 129.42857142857144, 'X[13] <= -0.532\\nentropy = 0.104\\nsamples = 146\\nvalue = [2, 144]'),\n",
       " Text(97.42112542372882, 119.07428571428571, 'entropy = 0.402\\nsamples = 25\\nvalue = [2, 23]'),\n",
       " Text(98.14747118644068, 119.07428571428571, 'entropy = 0.0\\nsamples = 121\\nvalue = [0, 121]'),\n",
       " Text(99.60016271186441, 129.42857142857144, 'X[4] <= 1.373\\nentropy = 0.005\\nsamples = 6949\\nvalue = [3, 6946]'),\n",
       " Text(98.87381694915256, 119.07428571428571, 'X[8] <= 2.742\\nentropy = 0.002\\nsamples = 6222\\nvalue = [1, 6221]'),\n",
       " Text(98.51064406779662, 108.72, 'entropy = 0.0\\nsamples = 5946\\nvalue = [0, 5946]'),\n",
       " Text(99.23698983050848, 108.72, 'X[12] <= -1.079\\nentropy = 0.035\\nsamples = 276\\nvalue = [1, 275]'),\n",
       " Text(98.87381694915256, 98.36571428571429, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(99.60016271186441, 98.36571428571429, 'entropy = 0.0\\nsamples = 251\\nvalue = [0, 251]'),\n",
       " Text(100.32650847457627, 119.07428571428571, 'X[8] <= 0.673\\nentropy = 0.027\\nsamples = 727\\nvalue = [2, 725]'),\n",
       " Text(99.96333559322035, 108.72, 'entropy = 0.0\\nsamples = 473\\nvalue = [0, 473]'),\n",
       " Text(100.68968135593221, 108.72, 'X[7] <= 0.097\\nentropy = 0.066\\nsamples = 254\\nvalue = [2, 252]'),\n",
       " Text(100.32650847457627, 98.36571428571429, 'X[7] <= -0.017\\nentropy = 0.172\\nsamples = 78\\nvalue = [2, 76]'),\n",
       " Text(99.96333559322035, 88.01142857142858, 'entropy = 0.0\\nsamples = 53\\nvalue = [0, 53]'),\n",
       " Text(100.68968135593221, 88.01142857142858, 'entropy = 0.402\\nsamples = 25\\nvalue = [2, 23]'),\n",
       " Text(101.05285423728814, 98.36571428571429, 'entropy = 0.0\\nsamples = 176\\nvalue = [0, 176]'),\n",
       " Text(102.14237288135594, 139.78285714285715, 'X[6] <= -1.05\\nentropy = 0.086\\nsamples = 650\\nvalue = [7, 643]'),\n",
       " Text(101.41602711864408, 129.42857142857144, 'X[2] <= -0.105\\nentropy = 0.331\\nsamples = 82\\nvalue = [5, 77]'),\n",
       " Text(101.05285423728814, 119.07428571428571, 'entropy = 0.0\\nsamples = 53\\nvalue = [0, 53]'),\n",
       " Text(101.7792, 119.07428571428571, 'entropy = 0.663\\nsamples = 29\\nvalue = [5, 24]'),\n",
       " Text(102.8687186440678, 129.42857142857144, 'X[10] <= 1.361\\nentropy = 0.034\\nsamples = 568\\nvalue = [2, 566]'),\n",
       " Text(102.50554576271188, 119.07428571428571, 'entropy = 0.0\\nsamples = 494\\nvalue = [0, 494]'),\n",
       " Text(103.23189152542373, 119.07428571428571, 'X[8] <= 0.127\\nentropy = 0.179\\nsamples = 74\\nvalue = [2, 72]'),\n",
       " Text(102.8687186440678, 108.72, 'entropy = 0.402\\nsamples = 25\\nvalue = [2, 23]'),\n",
       " Text(103.59506440677967, 108.72, 'entropy = 0.0\\nsamples = 49\\nvalue = [0, 49]'),\n",
       " Text(102.23316610169492, 170.84571428571428, 'X[2] <= -0.137\\nentropy = 0.693\\nsamples = 344\\nvalue = [64, 280]'),\n",
       " Text(101.50682033898306, 160.49142857142857, 'X[5] <= -1.16\\nentropy = 0.612\\nsamples = 73\\nvalue = [62, 11]'),\n",
       " Text(101.14364745762713, 150.13714285714286, 'entropy = 0.0\\nsamples = 47\\nvalue = [47, 0]'),\n",
       " Text(101.869993220339, 150.13714285714286, 'entropy = 0.983\\nsamples = 26\\nvalue = [15, 11]'),\n",
       " Text(102.95951186440679, 160.49142857142857, 'X[2] <= -0.098\\nentropy = 0.063\\nsamples = 271\\nvalue = [2, 269]'),\n",
       " Text(102.59633898305086, 150.13714285714286, 'entropy = 0.402\\nsamples = 25\\nvalue = [2, 23]'),\n",
       " Text(103.32268474576271, 150.13714285714286, 'entropy = 0.0\\nsamples = 246\\nvalue = [0, 246]'),\n",
       " Text(111.58486779661018, 181.2, 'X[3] <= -0.008\\nentropy = 0.451\\nsamples = 2280\\nvalue = [215, 2065]'),\n",
       " Text(106.50044745762713, 170.84571428571428, 'X[1] <= -0.232\\nentropy = 0.613\\nsamples = 1150\\nvalue = [174, 976]'),\n",
       " Text(104.77537627118645, 160.49142857142857, 'X[1] <= -0.235\\nentropy = 0.89\\nsamples = 202\\nvalue = [62, 140]'),\n",
       " Text(104.04903050847459, 150.13714285714286, 'X[13] <= -0.531\\nentropy = 0.719\\nsamples = 136\\nvalue = [27, 109]'),\n",
       " Text(103.68585762711865, 139.78285714285715, 'entropy = 0.303\\nsamples = 37\\nvalue = [2, 35]'),\n",
       " Text(104.41220338983052, 139.78285714285715, 'X[6] <= -1.186\\nentropy = 0.815\\nsamples = 99\\nvalue = [25, 74]'),\n",
       " Text(104.04903050847459, 129.42857142857144, 'entropy = 0.999\\nsamples = 27\\nvalue = [13, 14]'),\n",
       " Text(104.77537627118645, 129.42857142857144, 'X[4] <= -0.235\\nentropy = 0.65\\nsamples = 72\\nvalue = [12, 60]'),\n",
       " Text(104.41220338983052, 119.07428571428571, 'entropy = 0.845\\nsamples = 44\\nvalue = [12, 32]'),\n",
       " Text(105.13854915254238, 119.07428571428571, 'entropy = 0.0\\nsamples = 28\\nvalue = [0, 28]'),\n",
       " Text(105.50172203389832, 150.13714285714286, 'X[0] <= -0.117\\nentropy = 0.997\\nsamples = 66\\nvalue = [35, 31]'),\n",
       " Text(105.13854915254238, 139.78285714285715, 'entropy = 0.797\\nsamples = 29\\nvalue = [22, 7]'),\n",
       " Text(105.86489491525424, 139.78285714285715, 'entropy = 0.935\\nsamples = 37\\nvalue = [13, 24]'),\n",
       " Text(108.2255186440678, 160.49142857142857, 'X[2] <= -0.147\\nentropy = 0.524\\nsamples = 948\\nvalue = [112, 836]'),\n",
       " Text(106.95441355932205, 150.13714285714286, 'X[2] <= -0.16\\nentropy = 0.224\\nsamples = 277\\nvalue = [10, 267]'),\n",
       " Text(106.59124067796611, 139.78285714285715, 'entropy = 0.738\\nsamples = 48\\nvalue = [10, 38]'),\n",
       " Text(107.31758644067797, 139.78285714285715, 'entropy = 0.0\\nsamples = 229\\nvalue = [0, 229]'),\n",
       " Text(109.49662372881357, 150.13714285714286, 'X[2] <= -0.095\\nentropy = 0.615\\nsamples = 671\\nvalue = [102, 569]'),\n",
       " Text(108.04393220338984, 139.78285714285715, 'X[11] <= -0.75\\nentropy = 0.794\\nsamples = 338\\nvalue = [81, 257]'),\n",
       " Text(107.31758644067797, 129.42857142857144, 'X[1] <= -0.071\\nentropy = 0.604\\nsamples = 257\\nvalue = [38, 219]'),\n",
       " Text(106.95441355932205, 119.07428571428571, 'entropy = 1.0\\nsamples = 47\\nvalue = [23, 24]'),\n",
       " Text(107.68075932203391, 119.07428571428571, 'X[11] <= -1.048\\nentropy = 0.371\\nsamples = 210\\nvalue = [15, 195]'),\n",
       " Text(107.31758644067797, 108.72, 'X[1] <= 0.606\\nentropy = 0.633\\nsamples = 94\\nvalue = [15, 79]'),\n",
       " Text(106.95441355932205, 98.36571428571429, 'X[10] <= -0.847\\nentropy = 0.831\\nsamples = 57\\nvalue = [15, 42]'),\n",
       " Text(106.59124067796611, 88.01142857142858, 'entropy = 0.951\\nsamples = 27\\nvalue = [10, 17]'),\n",
       " Text(107.31758644067797, 88.01142857142858, 'entropy = 0.65\\nsamples = 30\\nvalue = [5, 25]'),\n",
       " Text(107.68075932203391, 98.36571428571429, 'entropy = 0.0\\nsamples = 37\\nvalue = [0, 37]'),\n",
       " Text(108.04393220338984, 108.72, 'entropy = 0.0\\nsamples = 116\\nvalue = [0, 116]'),\n",
       " Text(108.7702779661017, 129.42857142857144, 'X[12] <= -1.516\\nentropy = 0.997\\nsamples = 81\\nvalue = [43, 38]'),\n",
       " Text(108.40710508474577, 119.07428571428571, 'entropy = 0.281\\nsamples = 41\\nvalue = [39, 2]'),\n",
       " Text(109.13345084745764, 119.07428571428571, 'entropy = 0.469\\nsamples = 40\\nvalue = [4, 36]'),\n",
       " Text(110.94931525423729, 139.78285714285715, 'X[5] <= 1.608\\nentropy = 0.339\\nsamples = 333\\nvalue = [21, 312]'),\n",
       " Text(110.22296949152543, 129.42857142857144, 'X[8] <= 0.049\\nentropy = 0.183\\nsamples = 253\\nvalue = [7, 246]'),\n",
       " Text(109.8597966101695, 119.07428571428571, 'entropy = 0.592\\nsamples = 28\\nvalue = [4, 24]'),\n",
       " Text(110.58614237288137, 119.07428571428571, 'X[2] <= -0.027\\nentropy = 0.102\\nsamples = 225\\nvalue = [3, 222]'),\n",
       " Text(110.22296949152543, 108.72, 'entropy = 0.0\\nsamples = 165\\nvalue = [0, 165]'),\n",
       " Text(110.94931525423729, 108.72, 'X[12] <= -0.682\\nentropy = 0.286\\nsamples = 60\\nvalue = [3, 57]'),\n",
       " Text(110.58614237288137, 98.36571428571429, 'entropy = 0.529\\nsamples = 25\\nvalue = [3, 22]'),\n",
       " Text(111.31248813559323, 98.36571428571429, 'entropy = 0.0\\nsamples = 35\\nvalue = [0, 35]'),\n",
       " Text(111.67566101694916, 129.42857142857144, 'X[5] <= 1.887\\nentropy = 0.669\\nsamples = 80\\nvalue = [14, 66]'),\n",
       " Text(111.31248813559323, 119.07428571428571, 'entropy = 0.894\\nsamples = 45\\nvalue = [14, 31]'),\n",
       " Text(112.0388338983051, 119.07428571428571, 'entropy = 0.0\\nsamples = 35\\nvalue = [0, 35]'),\n",
       " Text(116.66928813559323, 170.84571428571428, 'X[5] <= 1.36\\nentropy = 0.225\\nsamples = 1130\\nvalue = [41, 1089]'),\n",
       " Text(115.48897627118644, 160.49142857142857, 'X[11] <= -0.895\\nentropy = 0.146\\nsamples = 959\\nvalue = [20, 939]'),\n",
       " Text(114.21787118644069, 150.13714285714286, 'X[12] <= -0.281\\nentropy = 0.275\\nsamples = 359\\nvalue = [17, 342]'),\n",
       " Text(113.49152542372882, 139.78285714285715, 'X[6] <= -1.27\\nentropy = 0.144\\nsamples = 294\\nvalue = [6, 288]'),\n",
       " Text(113.1283525423729, 129.42857142857144, 'X[9] <= -0.751\\nentropy = 0.29\\nsamples = 118\\nvalue = [6, 112]'),\n",
       " Text(112.76517966101696, 119.07428571428571, 'X[9] <= -1.162\\nentropy = 0.1\\nsamples = 77\\nvalue = [1, 76]'),\n",
       " Text(112.40200677966102, 108.72, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(113.1283525423729, 108.72, 'entropy = 0.0\\nsamples = 52\\nvalue = [0, 52]'),\n",
       " Text(113.49152542372882, 119.07428571428571, 'entropy = 0.535\\nsamples = 41\\nvalue = [5, 36]'),\n",
       " Text(113.85469830508475, 129.42857142857144, 'entropy = 0.0\\nsamples = 176\\nvalue = [0, 176]'),\n",
       " Text(114.94421694915255, 139.78285714285715, 'X[3] <= -0.007\\nentropy = 0.656\\nsamples = 65\\nvalue = [11, 54]'),\n",
       " Text(114.58104406779663, 129.42857142857144, 'entropy = 0.943\\nsamples = 25\\nvalue = [9, 16]'),\n",
       " Text(115.30738983050848, 129.42857142857144, 'entropy = 0.286\\nsamples = 40\\nvalue = [2, 38]'),\n",
       " Text(116.76008135593221, 150.13714285714286, 'X[10] <= -0.216\\nentropy = 0.045\\nsamples = 600\\nvalue = [3, 597]'),\n",
       " Text(116.39690847457628, 139.78285714285715, 'X[13] <= -0.527\\nentropy = 0.101\\nsamples = 229\\nvalue = [3, 226]'),\n",
       " Text(116.03373559322034, 129.42857142857144, 'X[10] <= -1.163\\nentropy = 0.194\\nsamples = 100\\nvalue = [3, 97]'),\n",
       " Text(115.67056271186442, 119.07428571428571, 'entropy = 0.0\\nsamples = 51\\nvalue = [0, 51]'),\n",
       " Text(116.39690847457628, 119.07428571428571, 'entropy = 0.332\\nsamples = 49\\nvalue = [3, 46]'),\n",
       " Text(116.76008135593221, 129.42857142857144, 'entropy = 0.0\\nsamples = 129\\nvalue = [0, 129]'),\n",
       " Text(117.12325423728815, 139.78285714285715, 'entropy = 0.0\\nsamples = 371\\nvalue = [0, 371]'),\n",
       " Text(117.84960000000001, 160.49142857142857, 'X[12] <= -1.231\\nentropy = 0.537\\nsamples = 171\\nvalue = [21, 150]'),\n",
       " Text(117.48642711864407, 150.13714285714286, 'entropy = 0.0\\nsamples = 35\\nvalue = [0, 35]'),\n",
       " Text(118.21277288135595, 150.13714285714286, 'X[10] <= 0.73\\nentropy = 0.621\\nsamples = 136\\nvalue = [21, 115]'),\n",
       " Text(117.84960000000001, 139.78285714285715, 'X[9] <= 1.294\\nentropy = 0.748\\nsamples = 89\\nvalue = [19, 70]'),\n",
       " Text(117.48642711864407, 129.42857142857144, 'X[2] <= -0.037\\nentropy = 0.835\\nsamples = 64\\nvalue = [17, 47]'),\n",
       " Text(117.12325423728815, 119.07428571428571, 'entropy = 0.592\\nsamples = 28\\nvalue = [4, 24]'),\n",
       " Text(117.84960000000001, 119.07428571428571, 'entropy = 0.944\\nsamples = 36\\nvalue = [13, 23]'),\n",
       " Text(118.21277288135595, 129.42857142857144, 'entropy = 0.402\\nsamples = 25\\nvalue = [2, 23]'),\n",
       " Text(118.57594576271187, 139.78285714285715, 'entropy = 0.254\\nsamples = 47\\nvalue = [2, 45]'),\n",
       " Text(229.49094756355933, 201.90857142857143, 'X[10] <= 0.415\\nentropy = 0.808\\nsamples = 23906\\nvalue = [5931, 17975]'),\n",
       " Text(158.00361101694915, 191.5542857142857, 'X[11] <= -0.051\\nentropy = 0.905\\nsamples = 13710\\nvalue = [4400, 9310]'),\n",
       " Text(129.7623088983051, 181.2, 'X[12] <= -0.163\\nentropy = 0.638\\nsamples = 3821\\nvalue = [618, 3203]'),\n",
       " Text(124.11433220338984, 170.84571428571428, 'X[8] <= -0.27\\nentropy = 0.797\\nsamples = 841\\nvalue = [203, 638]'),\n",
       " Text(121.66291525423729, 160.49142857142857, 'X[11] <= -0.562\\nentropy = 0.865\\nsamples = 627\\nvalue = [180, 447]'),\n",
       " Text(119.66546440677968, 150.13714285714286, 'X[4] <= -1.017\\nentropy = 0.619\\nsamples = 254\\nvalue = [39, 215]'),\n",
       " Text(119.30229152542374, 139.78285714285715, 'entropy = 0.144\\nsamples = 49\\nvalue = [1, 48]'),\n",
       " Text(120.0286372881356, 139.78285714285715, 'X[12] <= -1.783\\nentropy = 0.692\\nsamples = 205\\nvalue = [38, 167]'),\n",
       " Text(119.66546440677968, 129.42857142857144, 'entropy = 0.0\\nsamples = 26\\nvalue = [0, 26]'),\n",
       " Text(120.39181016949154, 129.42857142857144, 'X[11] <= -0.655\\nentropy = 0.746\\nsamples = 179\\nvalue = [38, 141]'),\n",
       " Text(119.66546440677968, 119.07428571428571, 'X[11] <= -0.728\\nentropy = 0.844\\nsamples = 125\\nvalue = [34, 91]'),\n",
       " Text(119.30229152542374, 108.72, 'X[11] <= -0.884\\nentropy = 0.726\\nsamples = 94\\nvalue = [19, 75]'),\n",
       " Text(118.9391186440678, 98.36571428571429, 'X[11] <= -1.115\\nentropy = 0.892\\nsamples = 55\\nvalue = [17, 38]'),\n",
       " Text(118.57594576271187, 88.01142857142858, 'entropy = 0.65\\nsamples = 30\\nvalue = [5, 25]'),\n",
       " Text(119.30229152542374, 88.01142857142858, 'entropy = 0.999\\nsamples = 25\\nvalue = [12, 13]'),\n",
       " Text(119.66546440677968, 98.36571428571429, 'entropy = 0.292\\nsamples = 39\\nvalue = [2, 37]'),\n",
       " Text(120.0286372881356, 108.72, 'entropy = 0.999\\nsamples = 31\\nvalue = [15, 16]'),\n",
       " Text(121.1181559322034, 119.07428571428571, 'X[3] <= -0.01\\nentropy = 0.381\\nsamples = 54\\nvalue = [4, 50]'),\n",
       " Text(120.75498305084747, 108.72, 'entropy = 0.0\\nsamples = 29\\nvalue = [0, 29]'),\n",
       " Text(121.48132881355933, 108.72, 'entropy = 0.634\\nsamples = 25\\nvalue = [4, 21]'),\n",
       " Text(123.66036610169492, 150.13714285714286, 'X[11] <= -0.525\\nentropy = 0.957\\nsamples = 373\\nvalue = [141, 232]'),\n",
       " Text(123.297193220339, 139.78285714285715, 'entropy = 0.706\\nsamples = 26\\nvalue = [21, 5]'),\n",
       " Text(124.02353898305086, 139.78285714285715, 'X[0] <= -0.213\\nentropy = 0.93\\nsamples = 347\\nvalue = [120, 227]'),\n",
       " Text(123.297193220339, 129.42857142857144, 'X[2] <= 0.036\\nentropy = 0.866\\nsamples = 233\\nvalue = [67, 166]'),\n",
       " Text(122.93402033898306, 119.07428571428571, 'X[2] <= -0.127\\nentropy = 0.809\\nsamples = 205\\nvalue = [51, 154]'),\n",
       " Text(122.2076745762712, 108.72, 'X[11] <= -0.317\\nentropy = 0.984\\nsamples = 54\\nvalue = [23, 31]'),\n",
       " Text(121.84450169491527, 98.36571428571429, 'entropy = 0.795\\nsamples = 25\\nvalue = [6, 19]'),\n",
       " Text(122.57084745762712, 98.36571428571429, 'entropy = 0.978\\nsamples = 29\\nvalue = [17, 12]'),\n",
       " Text(123.66036610169492, 108.72, 'X[13] <= 1.582\\nentropy = 0.692\\nsamples = 151\\nvalue = [28, 123]'),\n",
       " Text(123.297193220339, 98.36571428571429, 'X[6] <= 0.316\\nentropy = 0.753\\nsamples = 125\\nvalue = [27, 98]'),\n",
       " Text(122.57084745762712, 88.01142857142858, 'X[9] <= -0.834\\nentropy = 0.606\\nsamples = 74\\nvalue = [11, 63]'),\n",
       " Text(122.2076745762712, 77.65714285714284, 'entropy = 0.222\\nsamples = 28\\nvalue = [1, 27]'),\n",
       " Text(122.93402033898306, 77.65714285714284, 'entropy = 0.755\\nsamples = 46\\nvalue = [10, 36]'),\n",
       " Text(124.02353898305086, 88.01142857142858, 'X[12] <= -0.652\\nentropy = 0.897\\nsamples = 51\\nvalue = [16, 35]'),\n",
       " Text(123.66036610169492, 77.65714285714284, 'entropy = 0.971\\nsamples = 25\\nvalue = [10, 15]'),\n",
       " Text(124.38671186440679, 77.65714285714284, 'entropy = 0.779\\nsamples = 26\\nvalue = [6, 20]'),\n",
       " Text(124.02353898305086, 98.36571428571429, 'entropy = 0.235\\nsamples = 26\\nvalue = [1, 25]'),\n",
       " Text(123.66036610169492, 119.07428571428571, 'entropy = 0.985\\nsamples = 28\\nvalue = [16, 12]'),\n",
       " Text(124.74988474576273, 129.42857142857144, 'X[13] <= -0.535\\nentropy = 0.996\\nsamples = 114\\nvalue = [53, 61]'),\n",
       " Text(124.38671186440679, 119.07428571428571, 'entropy = 0.837\\nsamples = 30\\nvalue = [22, 8]'),\n",
       " Text(125.11305762711865, 119.07428571428571, 'X[2] <= -0.075\\nentropy = 0.95\\nsamples = 84\\nvalue = [31, 53]'),\n",
       " Text(124.74988474576273, 108.72, 'entropy = 0.971\\nsamples = 30\\nvalue = [18, 12]'),\n",
       " Text(125.47623050847459, 108.72, 'X[9] <= -0.363\\nentropy = 0.796\\nsamples = 54\\nvalue = [13, 41]'),\n",
       " Text(125.11305762711865, 98.36571428571429, 'entropy = 0.491\\nsamples = 28\\nvalue = [3, 25]'),\n",
       " Text(125.83940338983052, 98.36571428571429, 'entropy = 0.961\\nsamples = 26\\nvalue = [10, 16]'),\n",
       " Text(126.56574915254238, 160.49142857142857, 'X[12] <= -0.548\\nentropy = 0.492\\nsamples = 214\\nvalue = [23, 191]'),\n",
       " Text(126.20257627118644, 150.13714285714286, 'X[7] <= 1.571\\nentropy = 0.321\\nsamples = 171\\nvalue = [10, 161]'),\n",
       " Text(125.83940338983052, 139.78285714285715, 'X[11] <= -0.19\\nentropy = 0.118\\nsamples = 125\\nvalue = [2, 123]'),\n",
       " Text(125.47623050847459, 129.42857142857144, 'entropy = 0.0\\nsamples = 100\\nvalue = [0, 100]'),\n",
       " Text(126.20257627118644, 129.42857142857144, 'entropy = 0.402\\nsamples = 25\\nvalue = [2, 23]'),\n",
       " Text(126.56574915254238, 139.78285714285715, 'entropy = 0.667\\nsamples = 46\\nvalue = [8, 38]'),\n",
       " Text(126.92892203389832, 150.13714285714286, 'entropy = 0.884\\nsamples = 43\\nvalue = [13, 30]'),\n",
       " Text(135.41028559322035, 170.84571428571428, 'X[1] <= -0.468\\nentropy = 0.582\\nsamples = 2980\\nvalue = [415, 2565]'),\n",
       " Text(128.38161355932203, 160.49142857142857, 'X[11] <= -0.53\\nentropy = 0.882\\nsamples = 213\\nvalue = [64, 149]'),\n",
       " Text(127.65526779661018, 150.13714285714286, 'X[3] <= -0.011\\nentropy = 0.678\\nsamples = 123\\nvalue = [22, 101]'),\n",
       " Text(127.29209491525425, 139.78285714285715, 'entropy = 0.191\\nsamples = 34\\nvalue = [1, 33]'),\n",
       " Text(128.0184406779661, 139.78285714285715, 'X[3] <= -0.008\\nentropy = 0.788\\nsamples = 89\\nvalue = [21, 68]'),\n",
       " Text(127.65526779661018, 129.42857142857144, 'X[5] <= 0.167\\nentropy = 0.895\\nsamples = 61\\nvalue = [19, 42]'),\n",
       " Text(127.29209491525425, 119.07428571428571, 'entropy = 0.65\\nsamples = 36\\nvalue = [6, 30]'),\n",
       " Text(128.0184406779661, 119.07428571428571, 'entropy = 0.999\\nsamples = 25\\nvalue = [13, 12]'),\n",
       " Text(128.38161355932203, 129.42857142857144, 'entropy = 0.371\\nsamples = 28\\nvalue = [2, 26]'),\n",
       " Text(129.1079593220339, 150.13714285714286, 'X[7] <= -0.742\\nentropy = 0.997\\nsamples = 90\\nvalue = [42, 48]'),\n",
       " Text(128.74478644067798, 139.78285714285715, 'entropy = 0.8\\nsamples = 37\\nvalue = [28, 9]'),\n",
       " Text(129.47113220338983, 139.78285714285715, 'X[2] <= -0.057\\nentropy = 0.833\\nsamples = 53\\nvalue = [14, 39]'),\n",
       " Text(129.1079593220339, 129.42857142857144, 'entropy = 0.491\\nsamples = 28\\nvalue = [3, 25]'),\n",
       " Text(129.83430508474578, 129.42857142857144, 'entropy = 0.99\\nsamples = 25\\nvalue = [11, 14]'),\n",
       " Text(142.43895762711867, 160.49142857142857, 'X[6] <= 1.001\\nentropy = 0.549\\nsamples = 2767\\nvalue = [351, 2416]'),\n",
       " Text(137.0211559322034, 150.13714285714286, 'X[6] <= 0.69\\nentropy = 0.586\\nsamples = 2192\\nvalue = [308, 1884]'),\n",
       " Text(132.97234576271188, 139.78285714285715, 'X[9] <= -1.218\\nentropy = 0.516\\nsamples = 1300\\nvalue = [150, 1150]'),\n",
       " Text(130.56065084745762, 129.42857142857144, 'X[11] <= -0.541\\nentropy = 0.192\\nsamples = 169\\nvalue = [5, 164]'),\n",
       " Text(130.1974779661017, 119.07428571428571, 'entropy = 0.0\\nsamples = 95\\nvalue = [0, 95]'),\n",
       " Text(130.92382372881357, 119.07428571428571, 'X[11] <= -0.406\\nentropy = 0.357\\nsamples = 74\\nvalue = [5, 69]'),\n",
       " Text(130.56065084745762, 108.72, 'entropy = 0.619\\nsamples = 26\\nvalue = [4, 22]'),\n",
       " Text(131.2869966101695, 108.72, 'entropy = 0.146\\nsamples = 48\\nvalue = [1, 47]'),\n",
       " Text(135.3840406779661, 129.42857142857144, 'X[5] <= 1.262\\nentropy = 0.552\\nsamples = 1131\\nvalue = [145, 986]'),\n",
       " Text(133.89730169491526, 119.07428571428571, 'X[13] <= 1.927\\nentropy = 0.586\\nsamples = 1010\\nvalue = [142, 868]'),\n",
       " Text(132.01334237288137, 108.72, 'X[0] <= -0.213\\nentropy = 0.628\\nsamples = 825\\nvalue = [130, 695]'),\n",
       " Text(129.6981152542373, 98.36571428571429, 'X[11] <= -1.072\\nentropy = 0.571\\nsamples = 629\\nvalue = [85, 544]'),\n",
       " Text(128.97176949152544, 88.01142857142858, 'X[13] <= -0.529\\nentropy = 0.209\\nsamples = 91\\nvalue = [3, 88]'),\n",
       " Text(128.6085966101695, 77.65714285714284, 'entropy = 0.414\\nsamples = 36\\nvalue = [3, 33]'),\n",
       " Text(129.33494237288136, 77.65714285714284, 'entropy = 0.0\\nsamples = 55\\nvalue = [0, 55]'),\n",
       " Text(130.42446101694915, 88.01142857142858, 'X[11] <= -0.111\\nentropy = 0.616\\nsamples = 538\\nvalue = [82, 456]'),\n",
       " Text(130.06128813559323, 77.65714285714284, 'X[2] <= -0.109\\nentropy = 0.637\\nsamples = 509\\nvalue = [82, 427]'),\n",
       " Text(128.6993898305085, 67.30285714285714, 'X[4] <= 0.838\\nentropy = 0.776\\nsamples = 179\\nvalue = [41, 138]'),\n",
       " Text(127.97304406779662, 56.94857142857143, 'X[5] <= 0.552\\nentropy = 0.604\\nsamples = 115\\nvalue = [17, 98]'),\n",
       " Text(127.60987118644069, 46.59428571428572, 'X[3] <= -0.011\\nentropy = 0.401\\nsamples = 88\\nvalue = [7, 81]'),\n",
       " Text(127.24669830508475, 36.24000000000001, 'entropy = 0.624\\nsamples = 45\\nvalue = [7, 38]'),\n",
       " Text(127.97304406779662, 36.24000000000001, 'entropy = 0.0\\nsamples = 43\\nvalue = [0, 43]'),\n",
       " Text(128.33621694915254, 46.59428571428572, 'entropy = 0.951\\nsamples = 27\\nvalue = [10, 17]'),\n",
       " Text(129.42573559322034, 56.94857142857143, 'X[10] <= -1.163\\nentropy = 0.954\\nsamples = 64\\nvalue = [24, 40]'),\n",
       " Text(129.06256271186442, 46.59428571428572, 'entropy = 0.634\\nsamples = 25\\nvalue = [4, 21]'),\n",
       " Text(129.7889084745763, 46.59428571428572, 'entropy = 1.0\\nsamples = 39\\nvalue = [20, 19]'),\n",
       " Text(131.42318644067797, 67.30285714285714, 'X[11] <= -0.915\\nentropy = 0.541\\nsamples = 330\\nvalue = [41, 289]'),\n",
       " Text(131.06001355932204, 56.94857142857143, 'entropy = 0.904\\nsamples = 25\\nvalue = [8, 17]'),\n",
       " Text(131.78635932203392, 56.94857142857143, 'X[5] <= -0.03\\nentropy = 0.494\\nsamples = 305\\nvalue = [33, 272]'),\n",
       " Text(130.51525423728813, 46.59428571428572, 'X[13] <= -0.525\\nentropy = 0.282\\nsamples = 143\\nvalue = [7, 136]'),\n",
       " Text(129.7889084745763, 36.24000000000001, 'X[1] <= -0.458\\nentropy = 0.09\\nsamples = 88\\nvalue = [1, 87]'),\n",
       " Text(129.42573559322034, 25.8857142857143, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(130.1520813559322, 25.8857142857143, 'entropy = 0.0\\nsamples = 63\\nvalue = [0, 63]'),\n",
       " Text(131.2416, 36.24000000000001, 'X[3] <= -0.009\\nentropy = 0.497\\nsamples = 55\\nvalue = [6, 49]'),\n",
       " Text(130.87842711864408, 25.8857142857143, 'entropy = 0.722\\nsamples = 30\\nvalue = [6, 24]'),\n",
       " Text(131.60477288135596, 25.8857142857143, 'entropy = 0.0\\nsamples = 25\\nvalue = [0, 25]'),\n",
       " Text(133.05746440677967, 46.59428571428572, 'X[4] <= 1.217\\nentropy = 0.635\\nsamples = 162\\nvalue = [26, 136]'),\n",
       " Text(132.69429152542375, 36.24000000000001, 'X[5] <= 0.831\\nentropy = 0.544\\nsamples = 128\\nvalue = [16, 112]'),\n",
       " Text(132.3311186440678, 25.8857142857143, 'X[3] <= -0.01\\nentropy = 0.394\\nsamples = 90\\nvalue = [7, 83]'),\n",
       " Text(131.96794576271188, 15.531428571428563, 'entropy = 0.696\\nsamples = 32\\nvalue = [6, 26]'),\n",
       " Text(132.69429152542375, 15.531428571428563, 'X[11] <= -0.394\\nentropy = 0.126\\nsamples = 58\\nvalue = [1, 57]'),\n",
       " Text(132.3311186440678, 5.177142857142854, 'entropy = 0.0\\nsamples = 33\\nvalue = [0, 33]'),\n",
       " Text(133.05746440677967, 5.177142857142854, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(133.05746440677967, 25.8857142857143, 'entropy = 0.79\\nsamples = 38\\nvalue = [9, 29]'),\n",
       " Text(133.4206372881356, 36.24000000000001, 'entropy = 0.874\\nsamples = 34\\nvalue = [10, 24]'),\n",
       " Text(130.7876338983051, 77.65714285714284, 'entropy = 0.0\\nsamples = 29\\nvalue = [0, 29]'),\n",
       " Text(134.32856949152543, 98.36571428571429, 'X[0] <= 0.173\\nentropy = 0.777\\nsamples = 196\\nvalue = [45, 151]'),\n",
       " Text(133.9653966101695, 88.01142857142858, 'X[7] <= 0.639\\nentropy = 0.838\\nsamples = 157\\nvalue = [42, 115]'),\n",
       " Text(133.23905084745763, 77.65714285714284, 'X[12] <= 0.88\\nentropy = 0.702\\nsamples = 105\\nvalue = [20, 85]'),\n",
       " Text(132.8758779661017, 67.30285714285714, 'X[6] <= 0.164\\nentropy = 0.811\\nsamples = 72\\nvalue = [18, 54]'),\n",
       " Text(132.51270508474576, 56.94857142857143, 'entropy = 0.94\\nsamples = 42\\nvalue = [15, 27]'),\n",
       " Text(133.23905084745763, 56.94857142857143, 'entropy = 0.469\\nsamples = 30\\nvalue = [3, 27]'),\n",
       " Text(133.60222372881356, 67.30285714285714, 'entropy = 0.33\\nsamples = 33\\nvalue = [2, 31]'),\n",
       " Text(134.69174237288138, 77.65714285714284, 'X[4] <= -0.784\\nentropy = 0.983\\nsamples = 52\\nvalue = [22, 30]'),\n",
       " Text(134.32856949152543, 67.30285714285714, 'entropy = 0.779\\nsamples = 26\\nvalue = [6, 20]'),\n",
       " Text(135.0549152542373, 67.30285714285714, 'entropy = 0.961\\nsamples = 26\\nvalue = [16, 10]'),\n",
       " Text(134.69174237288138, 88.01142857142858, 'entropy = 0.391\\nsamples = 39\\nvalue = [3, 36]'),\n",
       " Text(135.78126101694917, 108.72, 'X[11] <= -0.515\\nentropy = 0.346\\nsamples = 185\\nvalue = [12, 173]'),\n",
       " Text(135.41808813559322, 98.36571428571429, 'entropy = 0.0\\nsamples = 83\\nvalue = [0, 83]'),\n",
       " Text(136.1444338983051, 98.36571428571429, 'X[3] <= -0.01\\nentropy = 0.523\\nsamples = 102\\nvalue = [12, 90]'),\n",
       " Text(135.78126101694917, 88.01142857142858, 'X[11] <= -0.264\\nentropy = 0.295\\nsamples = 77\\nvalue = [4, 73]'),\n",
       " Text(135.41808813559322, 77.65714285714284, 'entropy = 0.461\\nsamples = 41\\nvalue = [4, 37]'),\n",
       " Text(136.1444338983051, 77.65714285714284, 'entropy = 0.0\\nsamples = 36\\nvalue = [0, 36]'),\n",
       " Text(136.50760677966102, 88.01142857142858, 'entropy = 0.904\\nsamples = 25\\nvalue = [8, 17]'),\n",
       " Text(136.87077966101697, 119.07428571428571, 'X[11] <= -0.886\\nentropy = 0.168\\nsamples = 121\\nvalue = [3, 118]'),\n",
       " Text(136.50760677966102, 108.72, 'entropy = 0.48\\nsamples = 29\\nvalue = [3, 26]'),\n",
       " Text(137.2339525423729, 108.72, 'entropy = 0.0\\nsamples = 92\\nvalue = [0, 92]'),\n",
       " Text(141.06996610169492, 139.78285714285715, 'X[11] <= -0.966\\nentropy = 0.674\\nsamples = 892\\nvalue = [158, 734]'),\n",
       " Text(138.32347118644068, 129.42857142857144, 'X[3] <= -0.012\\nentropy = 0.89\\nsamples = 156\\nvalue = [48, 108]'),\n",
       " Text(137.96029830508476, 119.07428571428571, 'entropy = 0.999\\nsamples = 44\\nvalue = [23, 21]'),\n",
       " Text(138.6866440677966, 119.07428571428571, 'X[2] <= -0.079\\nentropy = 0.766\\nsamples = 112\\nvalue = [25, 87]'),\n",
       " Text(137.96029830508476, 108.72, 'X[13] <= -0.524\\nentropy = 0.637\\nsamples = 62\\nvalue = [10, 52]'),\n",
       " Text(137.5971254237288, 98.36571428571429, 'entropy = 0.345\\nsamples = 31\\nvalue = [2, 29]'),\n",
       " Text(138.32347118644068, 98.36571428571429, 'entropy = 0.824\\nsamples = 31\\nvalue = [8, 23]'),\n",
       " Text(139.41298983050848, 108.72, 'X[9] <= -0.639\\nentropy = 0.881\\nsamples = 50\\nvalue = [15, 35]'),\n",
       " Text(139.04981694915256, 98.36571428571429, 'entropy = 0.529\\nsamples = 25\\nvalue = [3, 22]'),\n",
       " Text(139.77616271186443, 98.36571428571429, 'entropy = 0.999\\nsamples = 25\\nvalue = [12, 13]'),\n",
       " Text(143.81646101694918, 129.42857142857144, 'X[11] <= -0.805\\nentropy = 0.608\\nsamples = 736\\nvalue = [110, 626]'),\n",
       " Text(143.45328813559323, 119.07428571428571, 'entropy = 0.0\\nsamples = 57\\nvalue = [0, 57]'),\n",
       " Text(144.1796338983051, 119.07428571428571, 'X[5] <= 0.931\\nentropy = 0.639\\nsamples = 679\\nvalue = [110, 569]'),\n",
       " Text(142.40916610169492, 108.72, 'X[5] <= -0.045\\nentropy = 0.688\\nsamples = 556\\nvalue = [102, 454]'),\n",
       " Text(140.50250847457627, 98.36571428571429, 'X[6] <= 0.825\\nentropy = 0.523\\nsamples = 297\\nvalue = [35, 262]'),\n",
       " Text(139.41298983050848, 88.01142857142858, 'X[1] <= -0.462\\nentropy = 0.6\\nsamples = 226\\nvalue = [33, 193]'),\n",
       " Text(138.32347118644068, 77.65714285714284, 'X[11] <= -0.574\\nentropy = 0.75\\nsamples = 84\\nvalue = [18, 66]'),\n",
       " Text(137.96029830508476, 67.30285714285714, 'entropy = 0.449\\nsamples = 32\\nvalue = [3, 29]'),\n",
       " Text(138.6866440677966, 67.30285714285714, 'X[11] <= -0.302\\nentropy = 0.867\\nsamples = 52\\nvalue = [15, 37]'),\n",
       " Text(138.32347118644068, 56.94857142857143, 'entropy = 0.904\\nsamples = 25\\nvalue = [8, 17]'),\n",
       " Text(139.04981694915256, 56.94857142857143, 'entropy = 0.826\\nsamples = 27\\nvalue = [7, 20]'),\n",
       " Text(140.50250847457627, 77.65714285714284, 'X[12] <= 1.475\\nentropy = 0.487\\nsamples = 142\\nvalue = [15, 127]'),\n",
       " Text(140.13933559322035, 67.30285714285714, 'X[3] <= -0.011\\nentropy = 0.559\\nsamples = 115\\nvalue = [15, 100]'),\n",
       " Text(139.77616271186443, 56.94857142857143, 'entropy = 0.768\\nsamples = 49\\nvalue = [11, 38]'),\n",
       " Text(140.50250847457627, 56.94857142857143, 'X[3] <= -0.01\\nentropy = 0.33\\nsamples = 66\\nvalue = [4, 62]'),\n",
       " Text(140.13933559322035, 46.59428571428572, 'entropy = 0.0\\nsamples = 30\\nvalue = [0, 30]'),\n",
       " Text(140.86568135593222, 46.59428571428572, 'entropy = 0.503\\nsamples = 36\\nvalue = [4, 32]'),\n",
       " Text(140.86568135593222, 67.30285714285714, 'entropy = 0.0\\nsamples = 27\\nvalue = [0, 27]'),\n",
       " Text(141.59202711864407, 88.01142857142858, 'X[6] <= 0.939\\nentropy = 0.185\\nsamples = 71\\nvalue = [2, 69]'),\n",
       " Text(141.22885423728815, 77.65714285714284, 'entropy = 0.0\\nsamples = 46\\nvalue = [0, 46]'),\n",
       " Text(141.95520000000002, 77.65714285714284, 'entropy = 0.402\\nsamples = 25\\nvalue = [2, 23]'),\n",
       " Text(144.31582372881357, 98.36571428571429, 'X[3] <= -0.009\\nentropy = 0.825\\nsamples = 259\\nvalue = [67, 192]'),\n",
       " Text(143.40789152542374, 88.01142857142858, 'X[9] <= -0.519\\nentropy = 0.728\\nsamples = 197\\nvalue = [40, 157]'),\n",
       " Text(142.68154576271186, 77.65714285714284, 'X[1] <= -0.449\\nentropy = 0.455\\nsamples = 94\\nvalue = [9, 85]'),\n",
       " Text(142.31837288135594, 67.30285714285714, 'X[12] <= 0.914\\nentropy = 0.141\\nsamples = 50\\nvalue = [1, 49]'),\n",
       " Text(141.95520000000002, 56.94857142857143, 'entropy = 0.0\\nsamples = 25\\nvalue = [0, 25]'),\n",
       " Text(142.68154576271186, 56.94857142857143, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(143.0447186440678, 67.30285714285714, 'entropy = 0.684\\nsamples = 44\\nvalue = [8, 36]'),\n",
       " Text(144.1342372881356, 77.65714285714284, 'X[3] <= -0.011\\nentropy = 0.882\\nsamples = 103\\nvalue = [31, 72]'),\n",
       " Text(143.77106440677966, 67.30285714285714, 'entropy = 0.602\\nsamples = 34\\nvalue = [5, 29]'),\n",
       " Text(144.49741016949153, 67.30285714285714, 'X[11] <= -0.287\\nentropy = 0.956\\nsamples = 69\\nvalue = [26, 43]'),\n",
       " Text(144.1342372881356, 56.94857142857143, 'entropy = 1.0\\nsamples = 42\\nvalue = [21, 21]'),\n",
       " Text(144.86058305084748, 56.94857142857143, 'entropy = 0.691\\nsamples = 27\\nvalue = [5, 22]'),\n",
       " Text(145.2237559322034, 88.01142857142858, 'X[9] <= -0.622\\nentropy = 0.988\\nsamples = 62\\nvalue = [27, 35]'),\n",
       " Text(144.86058305084748, 77.65714285714284, 'entropy = 0.94\\nsamples = 28\\nvalue = [10, 18]'),\n",
       " Text(145.58692881355933, 77.65714285714284, 'entropy = 1.0\\nsamples = 34\\nvalue = [17, 17]'),\n",
       " Text(145.95010169491528, 108.72, 'X[4] <= 0.397\\nentropy = 0.347\\nsamples = 123\\nvalue = [8, 115]'),\n",
       " Text(145.58692881355933, 98.36571428571429, 'entropy = 0.0\\nsamples = 47\\nvalue = [0, 47]'),\n",
       " Text(146.3132745762712, 98.36571428571429, 'X[7] <= -0.201\\nentropy = 0.485\\nsamples = 76\\nvalue = [8, 68]'),\n",
       " Text(145.95010169491528, 88.01142857142858, 'entropy = 0.206\\nsamples = 31\\nvalue = [1, 30]'),\n",
       " Text(146.67644745762712, 88.01142857142858, 'entropy = 0.624\\nsamples = 45\\nvalue = [7, 38]'),\n",
       " Text(147.85675932203392, 150.13714285714286, 'X[11] <= -0.408\\nentropy = 0.384\\nsamples = 575\\nvalue = [43, 532]'),\n",
       " Text(146.67644745762712, 139.78285714285715, 'X[3] <= -0.007\\nentropy = 0.095\\nsamples = 246\\nvalue = [3, 243]'),\n",
       " Text(146.3132745762712, 129.42857142857144, 'entropy = 0.0\\nsamples = 206\\nvalue = [0, 206]'),\n",
       " Text(147.03962033898307, 129.42857142857144, 'entropy = 0.384\\nsamples = 40\\nvalue = [3, 37]'),\n",
       " Text(149.0370711864407, 139.78285714285715, 'X[3] <= -0.01\\nentropy = 0.534\\nsamples = 329\\nvalue = [40, 289]'),\n",
       " Text(147.76596610169491, 129.42857142857144, 'X[13] <= 1.96\\nentropy = 0.658\\nsamples = 200\\nvalue = [34, 166]'),\n",
       " Text(147.03962033898307, 119.07428571428571, 'X[11] <= -0.287\\nentropy = 0.743\\nsamples = 147\\nvalue = [31, 116]'),\n",
       " Text(146.67644745762712, 108.72, 'entropy = 0.977\\nsamples = 34\\nvalue = [14, 20]'),\n",
       " Text(147.402793220339, 108.72, 'X[2] <= -0.096\\nentropy = 0.611\\nsamples = 113\\nvalue = [17, 96]'),\n",
       " Text(147.03962033898307, 98.36571428571429, 'entropy = 0.0\\nsamples = 36\\nvalue = [0, 36]'),\n",
       " Text(147.76596610169491, 98.36571428571429, 'X[3] <= -0.01\\nentropy = 0.762\\nsamples = 77\\nvalue = [17, 60]'),\n",
       " Text(147.402793220339, 88.01142857142858, 'X[9] <= -0.614\\nentropy = 0.904\\nsamples = 50\\nvalue = [16, 34]'),\n",
       " Text(147.03962033898307, 77.65714285714284, 'entropy = 0.999\\nsamples = 25\\nvalue = [12, 13]'),\n",
       " Text(147.76596610169491, 77.65714285714284, 'entropy = 0.634\\nsamples = 25\\nvalue = [4, 21]'),\n",
       " Text(148.12913898305086, 88.01142857142858, 'entropy = 0.229\\nsamples = 27\\nvalue = [1, 26]'),\n",
       " Text(148.4923118644068, 119.07428571428571, 'X[5] <= 0.422\\nentropy = 0.314\\nsamples = 53\\nvalue = [3, 50]'),\n",
       " Text(148.12913898305086, 108.72, 'entropy = 0.0\\nsamples = 28\\nvalue = [0, 28]'),\n",
       " Text(148.8554847457627, 108.72, 'entropy = 0.529\\nsamples = 25\\nvalue = [3, 22]'),\n",
       " Text(150.30817627118645, 129.42857142857144, 'X[4] <= 1.217\\nentropy = 0.271\\nsamples = 129\\nvalue = [6, 123]'),\n",
       " Text(149.94500338983053, 119.07428571428571, 'X[3] <= -0.009\\nentropy = 0.086\\nsamples = 93\\nvalue = [1, 92]'),\n",
       " Text(149.58183050847458, 108.72, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(150.30817627118645, 108.72, 'entropy = 0.0\\nsamples = 68\\nvalue = [0, 68]'),\n",
       " Text(150.67134915254238, 119.07428571428571, 'entropy = 0.581\\nsamples = 36\\nvalue = [5, 31]'),\n",
       " Text(186.24491313559324, 181.2, 'X[11] <= -0.04\\nentropy = 0.96\\nsamples = 9889\\nvalue = [3782, 6107]'),\n",
       " Text(155.39507923728814, 170.84571428571428, 'X[4] <= -1.611\\nentropy = 0.997\\nsamples = 2619\\nvalue = [1393, 1226]'),\n",
       " Text(151.39769491525425, 160.49142857142857, 'X[5] <= 0.619\\nentropy = 0.773\\nsamples = 88\\nvalue = [20, 68]'),\n",
       " Text(151.03452203389833, 150.13714285714286, 'entropy = 0.982\\nsamples = 38\\nvalue = [16, 22]'),\n",
       " Text(151.76086779661017, 150.13714285714286, 'X[9] <= -0.545\\nentropy = 0.402\\nsamples = 50\\nvalue = [4, 46]'),\n",
       " Text(151.39769491525425, 139.78285714285715, 'entropy = 0.242\\nsamples = 25\\nvalue = [1, 24]'),\n",
       " Text(152.12404067796612, 139.78285714285715, 'entropy = 0.529\\nsamples = 25\\nvalue = [3, 22]'),\n",
       " Text(159.39246355932204, 160.49142857142857, 'X[5] <= -0.447\\nentropy = 0.995\\nsamples = 2531\\nvalue = [1373, 1158]'),\n",
       " Text(155.21101016949154, 150.13714285714286, 'X[1] <= -0.427\\nentropy = 0.99\\nsamples = 545\\nvalue = [241, 304]'),\n",
       " Text(152.85038644067797, 139.78285714285715, 'X[12] <= 0.281\\nentropy = 1.0\\nsamples = 399\\nvalue = [202, 197]'),\n",
       " Text(151.76086779661017, 129.42857142857144, 'X[5] <= -0.704\\nentropy = 0.937\\nsamples = 119\\nvalue = [77, 42]'),\n",
       " Text(151.39769491525425, 119.07428571428571, 'X[5] <= -0.951\\nentropy = 0.837\\nsamples = 75\\nvalue = [55, 20]'),\n",
       " Text(151.03452203389833, 108.72, 'entropy = 0.933\\nsamples = 43\\nvalue = [28, 15]'),\n",
       " Text(151.76086779661017, 108.72, 'entropy = 0.625\\nsamples = 32\\nvalue = [27, 5]'),\n",
       " Text(152.12404067796612, 119.07428571428571, 'entropy = 1.0\\nsamples = 44\\nvalue = [22, 22]'),\n",
       " Text(153.9399050847458, 129.42857142857144, 'X[3] <= -0.009\\nentropy = 0.992\\nsamples = 280\\nvalue = [125, 155]'),\n",
       " Text(152.85038644067797, 119.07428571428571, 'X[9] <= -1.078\\nentropy = 0.953\\nsamples = 185\\nvalue = [69, 116]'),\n",
       " Text(152.48721355932204, 108.72, 'entropy = 0.61\\nsamples = 40\\nvalue = [6, 34]'),\n",
       " Text(153.21355932203392, 108.72, 'X[0] <= -0.213\\nentropy = 0.988\\nsamples = 145\\nvalue = [63, 82]'),\n",
       " Text(152.85038644067797, 98.36571428571429, 'X[4] <= 0.77\\nentropy = 0.949\\nsamples = 106\\nvalue = [39, 67]'),\n",
       " Text(152.48721355932204, 88.01142857142858, 'entropy = 0.773\\nsamples = 44\\nvalue = [10, 34]'),\n",
       " Text(153.21355932203392, 88.01142857142858, 'X[12] <= 0.925\\nentropy = 0.997\\nsamples = 62\\nvalue = [29, 33]'),\n",
       " Text(152.85038644067797, 77.65714285714284, 'entropy = 0.985\\nsamples = 35\\nvalue = [20, 15]'),\n",
       " Text(153.57673220338984, 77.65714285714284, 'entropy = 0.918\\nsamples = 27\\nvalue = [9, 18]'),\n",
       " Text(153.57673220338984, 98.36571428571429, 'entropy = 0.961\\nsamples = 39\\nvalue = [24, 15]'),\n",
       " Text(155.02942372881358, 119.07428571428571, 'X[5] <= -0.605\\nentropy = 0.977\\nsamples = 95\\nvalue = [56, 39]'),\n",
       " Text(154.66625084745763, 108.72, 'X[5] <= -1.029\\nentropy = 0.932\\nsamples = 69\\nvalue = [45, 24]'),\n",
       " Text(154.3030779661017, 98.36571428571429, 'entropy = 0.999\\nsamples = 27\\nvalue = [14, 13]'),\n",
       " Text(155.02942372881358, 98.36571428571429, 'entropy = 0.83\\nsamples = 42\\nvalue = [31, 11]'),\n",
       " Text(155.3925966101695, 108.72, 'entropy = 0.983\\nsamples = 26\\nvalue = [11, 15]'),\n",
       " Text(157.5716338983051, 139.78285714285715, 'X[7] <= 0.479\\nentropy = 0.837\\nsamples = 146\\nvalue = [39, 107]'),\n",
       " Text(157.20846101694917, 129.42857142857144, 'X[12] <= 0.917\\nentropy = 0.704\\nsamples = 115\\nvalue = [22, 93]'),\n",
       " Text(156.4821152542373, 119.07428571428571, 'X[9] <= -0.64\\nentropy = 0.863\\nsamples = 63\\nvalue = [18, 45]'),\n",
       " Text(156.11894237288138, 108.72, 'entropy = 0.994\\nsamples = 33\\nvalue = [15, 18]'),\n",
       " Text(156.84528813559322, 108.72, 'entropy = 0.469\\nsamples = 30\\nvalue = [3, 27]'),\n",
       " Text(157.93480677966102, 119.07428571428571, 'X[3] <= -0.01\\nentropy = 0.391\\nsamples = 52\\nvalue = [4, 48]'),\n",
       " Text(157.5716338983051, 108.72, 'entropy = 0.0\\nsamples = 27\\nvalue = [0, 27]'),\n",
       " Text(158.29797966101697, 108.72, 'entropy = 0.634\\nsamples = 25\\nvalue = [4, 21]'),\n",
       " Text(157.93480677966102, 129.42857142857144, 'entropy = 0.993\\nsamples = 31\\nvalue = [17, 14]'),\n",
       " Text(163.57391694915256, 150.13714285714286, 'X[9] <= 0.472\\nentropy = 0.986\\nsamples = 1986\\nvalue = [1132, 854]'),\n",
       " Text(163.2107440677966, 139.78285714285715, 'X[5] <= -0.35\\nentropy = 0.983\\nsamples = 1953\\nvalue = [1126, 827]'),\n",
       " Text(159.02432542372884, 129.42857142857144, 'X[5] <= -0.4\\nentropy = 0.75\\nsamples = 98\\nvalue = [77, 21]'),\n",
       " Text(158.6611525423729, 119.07428571428571, 'entropy = 0.959\\nsamples = 42\\nvalue = [26, 16]'),\n",
       " Text(159.38749830508476, 119.07428571428571, 'X[10] <= -0.847\\nentropy = 0.434\\nsamples = 56\\nvalue = [51, 5]'),\n",
       " Text(159.02432542372884, 108.72, 'entropy = 0.605\\nsamples = 27\\nvalue = [23, 4]'),\n",
       " Text(159.75067118644068, 108.72, 'entropy = 0.216\\nsamples = 29\\nvalue = [28, 1]'),\n",
       " Text(167.3971627118644, 129.42857142857144, 'X[9] <= -0.7\\nentropy = 0.988\\nsamples = 1855\\nvalue = [1049, 806]'),\n",
       " Text(162.51986440677967, 119.07428571428571, 'X[7] <= -0.188\\nentropy = 1.0\\nsamples = 704\\nvalue = [355, 349]'),\n",
       " Text(160.47701694915256, 108.72, 'X[5] <= 1.372\\nentropy = 0.974\\nsamples = 425\\nvalue = [172, 253]'),\n",
       " Text(159.29670508474578, 98.36571428571429, 'X[9] <= -1.186\\nentropy = 0.946\\nsamples = 368\\nvalue = [134, 234]'),\n",
       " Text(158.02560000000003, 88.01142857142858, 'X[3] <= -0.01\\nentropy = 0.997\\nsamples = 122\\nvalue = [65, 57]'),\n",
       " Text(157.29925423728815, 77.65714285714284, 'X[4] <= 1.201\\nentropy = 0.944\\nsamples = 72\\nvalue = [46, 26]'),\n",
       " Text(156.9360813559322, 67.30285714285714, 'entropy = 1.0\\nsamples = 41\\nvalue = [21, 20]'),\n",
       " Text(157.66242711864408, 67.30285714285714, 'entropy = 0.709\\nsamples = 31\\nvalue = [25, 6]'),\n",
       " Text(158.75194576271187, 77.65714285714284, 'X[3] <= -0.009\\nentropy = 0.958\\nsamples = 50\\nvalue = [19, 31]'),\n",
       " Text(158.38877288135595, 67.30285714285714, 'entropy = 0.722\\nsamples = 25\\nvalue = [5, 20]'),\n",
       " Text(159.11511864406782, 67.30285714285714, 'entropy = 0.99\\nsamples = 25\\nvalue = [14, 11]'),\n",
       " Text(160.56781016949154, 88.01142857142858, 'X[9] <= -0.768\\nentropy = 0.856\\nsamples = 246\\nvalue = [69, 177]'),\n",
       " Text(160.20463728813561, 77.65714285714284, 'X[0] <= -0.149\\nentropy = 0.813\\nsamples = 215\\nvalue = [54, 161]'),\n",
       " Text(159.84146440677966, 67.30285714285714, 'X[1] <= -0.422\\nentropy = 0.858\\nsamples = 181\\nvalue = [51, 130]'),\n",
       " Text(159.47829152542374, 56.94857142857143, 'X[2] <= -0.06\\nentropy = 0.914\\nsamples = 143\\nvalue = [47, 96]'),\n",
       " Text(158.75194576271187, 46.59428571428572, 'X[10] <= -0.847\\nentropy = 0.782\\nsamples = 86\\nvalue = [20, 66]'),\n",
       " Text(158.38877288135595, 36.24000000000001, 'X[9] <= -0.968\\nentropy = 0.886\\nsamples = 56\\nvalue = [17, 39]'),\n",
       " Text(158.02560000000003, 25.8857142857143, 'entropy = 0.722\\nsamples = 25\\nvalue = [5, 20]'),\n",
       " Text(158.75194576271187, 25.8857142857143, 'entropy = 0.963\\nsamples = 31\\nvalue = [12, 19]'),\n",
       " Text(159.11511864406782, 36.24000000000001, 'entropy = 0.469\\nsamples = 30\\nvalue = [3, 27]'),\n",
       " Text(160.20463728813561, 46.59428571428572, 'X[4] <= 0.224\\nentropy = 0.998\\nsamples = 57\\nvalue = [27, 30]'),\n",
       " Text(159.84146440677966, 36.24000000000001, 'entropy = 0.904\\nsamples = 25\\nvalue = [17, 8]'),\n",
       " Text(160.56781016949154, 36.24000000000001, 'entropy = 0.896\\nsamples = 32\\nvalue = [10, 22]'),\n",
       " Text(160.20463728813561, 56.94857142857143, 'entropy = 0.485\\nsamples = 38\\nvalue = [4, 34]'),\n",
       " Text(160.56781016949154, 67.30285714285714, 'entropy = 0.431\\nsamples = 34\\nvalue = [3, 31]'),\n",
       " Text(160.93098305084746, 77.65714285714284, 'entropy = 0.999\\nsamples = 31\\nvalue = [15, 16]'),\n",
       " Text(161.65732881355933, 98.36571428571429, 'X[5] <= 1.671\\nentropy = 0.918\\nsamples = 57\\nvalue = [38, 19]'),\n",
       " Text(161.2941559322034, 88.01142857142858, 'entropy = 0.579\\nsamples = 29\\nvalue = [25, 4]'),\n",
       " Text(162.02050169491525, 88.01142857142858, 'entropy = 0.996\\nsamples = 28\\nvalue = [13, 15]'),\n",
       " Text(164.5627118644068, 108.72, 'X[13] <= 2.223\\nentropy = 0.929\\nsamples = 279\\nvalue = [183, 96]'),\n",
       " Text(164.19953898305087, 98.36571428571429, 'X[12] <= 0.632\\nentropy = 0.892\\nsamples = 249\\nvalue = [172, 77]'),\n",
       " Text(162.74684745762713, 88.01142857142858, 'X[2] <= -0.074\\nentropy = 0.966\\nsamples = 138\\nvalue = [84, 54]'),\n",
       " Text(162.02050169491525, 77.65714285714284, 'X[6] <= 0.549\\nentropy = 0.993\\nsamples = 60\\nvalue = [27, 33]'),\n",
       " Text(161.65732881355933, 67.30285714285714, 'entropy = 0.855\\nsamples = 25\\nvalue = [7, 18]'),\n",
       " Text(162.3836745762712, 67.30285714285714, 'entropy = 0.985\\nsamples = 35\\nvalue = [20, 15]'),\n",
       " ...]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plot_tree(modelDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True False ...  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# Use the trained tree to predict the testing data\n",
    "dt_pred = modelDT.predict(X_test)\n",
    "dt_pred_prob = modelDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Metrics\n",
      "Accuracy: 0.8752067167027096\n",
      "Balanced accuracy: 0.7052392522783838\n"
     ]
    }
   ],
   "source": [
    "# Run this block for model evaluation \n",
    "from sklearn import metrics\n",
    "print(\"Model Metrics\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, dt_pred))\n",
    "print(\"Balanced accuracy:\", metrics.balanced_accuracy_score(y_test, dt_pred))\n",
    "#print('Precision score for \"Yes\"' , metrics.precision_score(y_test, dt_pred, pos_label = \"True\"))\n",
    "#print('Recall score for \"No\"' , metrics.recall_score(y_test, dt_pred, pos_label = \"False\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1610  1856]\n",
      " [ 1087 19030]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, dt_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.60      0.46      0.52      3466\n",
      "        True       0.91      0.95      0.93     20117\n",
      "\n",
      "    accuracy                           0.88     23583\n",
      "   macro avg       0.75      0.71      0.73     23583\n",
      "weighted avg       0.86      0.88      0.87     23583\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, dt_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "\n",
    "Hyperparameters:\n",
    "- number of features per tree\n",
    "- number of trees per forest (n_estimators)\n",
    "- depth(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tree_grid = [10,50,100,200,250,500]\n",
    "crit_grid = ['gini', 'entropy']\n",
    "max_depth_grid = ['None', 3, 5, 10, 15, 20]\n",
    "min_sample_split_grid = [2, 5, 10, 20]\n",
    "min_samples_leaf_grid = [2, 5, 10, 25, 50]\n",
    "feature_grid = [\"auto\", \"log2\", 4, 5, 10, 12, 15, 20]\n",
    "\n",
    "rfc_grid = {'n_estimators':n_tree_grid,\n",
    "              'criterion': crit_grid, \n",
    "              'max_depth':max_depth_grid,\n",
    "              'min_samples_split':min_sample_split_grid,\n",
    "              'min_samples_leaf':min_samples_leaf_grid,\n",
    "              'max_features':feature_grid }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearch time:  1833.1879992485046\n"
     ]
    }
   ],
   "source": [
    "forest = RandomForestClassifier()\n",
    "start = time.time()\n",
    "forest_cv = RandomizedSearchCV(forest, rfc_grid, cv=5)\n",
    "forest_cv.fit(X_train, y)\n",
    "end = time.time()\n",
    "print(\"GridSearch time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params:  {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 2, 'max_features': 10, 'max_depth': 15, 'criterion': 'gini'}\n",
      "Best score:  0.8997183098591549\n"
     ]
    }
   ],
   "source": [
    "print(\"Best params: \" , forest_cv.best_params_)\n",
    "print(\"Best score: \", forest_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
       "                       criterion='gini', max_depth=15, max_features=10,\n",
       "                       max_leaf_nodes=None, max_samples=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=2, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelRF = RandomForestClassifier(n_estimators = 200, min_samples_split=2, \n",
    "                                 min_samples_leaf=2, max_features=10,\n",
    "                                max_depth=15, criterion='gini')\n",
    "modelRF.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = modelRF.predict(X_test)\n",
    "rf_pred_prob = modelRF.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier model\n",
      "Accuracy: 0.9109528049866429\n",
      "Balanced accuracy: 0.7298932018034946\n"
     ]
    }
   ],
   "source": [
    "print(\"Random Forest Classifier model\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, rf_pred))\n",
    "print(\"Balanced accuracy:\", metrics.balanced_accuracy_score(y_test, rf_pred))\n",
    "#print('Precision score' , metrics.precision_score(y_test, rf_pred, pos_label = \"Yes\"))\n",
    "#print('Recall score' , metrics.recall_score(y_test, rf_pred, pos_label = \"No\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1641  1825]\n",
      " [  275 19842]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      0.47      0.61      3466\n",
      "        True       0.92      0.99      0.95     20117\n",
      "\n",
      "    accuracy                           0.91     23583\n",
      "   macro avg       0.89      0.73      0.78     23583\n",
      "weighted avg       0.91      0.91      0.90     23583\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regression\n",
    "- n_estimators (default = 100)\n",
    "- max_depth\n",
    "- min_samples_split\n",
    "- min_samples_leaf\n",
    "- max_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tree_grid = [10,50,100,200,250,500]\n",
    "crit_grid = ['mse', 'mae']\n",
    "max_depth_grid = ['None', 3, 5, 10, 15, 20]\n",
    "min_sample_split_grid = [2, 5, 10, 20]\n",
    "min_samples_leaf_grid = [2, 5, 10, 25, 50]\n",
    "feature_grid = [\"auto\", \"log2\", 4, 5, 10, 12, 15, 20]\n",
    "\n",
    "rfr_grid = {'n_estimators':n_tree_grid,\n",
    "              'criterion': crit_grid, \n",
    "              'max_depth':max_depth_grid,\n",
    "              'min_samples_split':min_sample_split_grid,\n",
    "              'min_samples_leaf':min_samples_leaf_grid,\n",
    "              'max_features':feature_grid }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    }
   ],
   "source": [
    "forestReg = RandomForestRegressor()\n",
    "start = time.time()\n",
    "forestreg_cv = RandomizedSearchCV(forestReg, rfr_grid, cv=5)\n",
    "forestreg_cv.fit(X_train, y)\n",
    "end = time.time()\n",
    "print(\"GridSearch time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best params: \" , forestreg_cv.best_params_)\n",
    "print(\"Best score: \", forestreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelRFR = RandomForestRegressor(n_estimators =_, ...)\n",
    "modelRFR.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfr_pred = modelRFR.predict(X_test)\n",
    "rfr_pred_prob = modelRFR.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest Regression model\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, rfr_pred))\n",
    "print(\"Balanced accuracy:\", metrics.balanced_accuracy_score(y_test, rfr_pred))\n",
    "#print('Precision score' , metrics.precision_score(y_test, rf_pred, pos_label = \"Yes\"))\n",
    "#print('Recall score' , metrics.recall_score(y_test, rf_pred, pos_label = \"No\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, rfr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, rfr_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
