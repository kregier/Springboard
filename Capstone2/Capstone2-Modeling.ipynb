{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the environment\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the data\n",
    "training = pd.read_csv('data/processed/training.csv', index_col=0)\n",
    "\n",
    "y_train = training['CURROPER']\n",
    "X_train = training.drop('CURROPER', axis=1)\n",
    "\n",
    "testing = pd.read_csv('data/processed/training.csv', index_col=0)\n",
    "y_test = testing['CURROPER']\n",
    "X_test = testing.drop('CURROPER', axis=1)\n",
    "\n",
    "# X_train = pd.read_csv('data/processed/X_train.csv', index_col=0)\n",
    "# X_test = pd.read_csv('data/processed/X_test.csv', index_col=0)\n",
    "# y_train = pd.read_csv('data/processed/y_train.csv', index_col=0)\n",
    "# y_test = pd.read_csv('data/processed/y_test.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 55025 entries, 2905 to 78034\n",
      "Data columns (total 21 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   NUMBRANCH          55025 non-null  float64\n",
      " 1   UGDS               55025 non-null  float64\n",
      " 2   TUITFTE            55025 non-null  float64\n",
      " 3   INEXPFTE           55025 non-null  float64\n",
      " 4   PFTFAC             55025 non-null  float64\n",
      " 5   UG25abv            55025 non-null  float64\n",
      " 6   COMP_ORIG_YR4_RT   55025 non-null  float64\n",
      " 7   WDRAW_ORIG_YR4_RT  55025 non-null  float64\n",
      " 8   ENRL_ORIG_YR4_RT   55025 non-null  float64\n",
      " 9   DEBT_MDN           55025 non-null  float64\n",
      " 10  Year               55025 non-null  float64\n",
      " 11  Cost               55025 non-null  float64\n",
      " 12  Complete           55025 non-null  float64\n",
      " 13  RetentionFT        55025 non-null  float64\n",
      " 14  PREDDEG_1          55025 non-null  float64\n",
      " 15  PREDDEG_2          55025 non-null  float64\n",
      " 16  PREDDEG_3          55025 non-null  float64\n",
      " 17  PREDDEG_4          55025 non-null  float64\n",
      " 18  CONTROL_2.0        55025 non-null  float64\n",
      " 19  CONTROL_3.0        55025 non-null  float64\n",
      " 20  CURROPER           38582 non-null  object \n",
      "dtypes: float64(20), object(1)\n",
      "memory usage: 9.2+ MB\n"
     ]
    }
   ],
   "source": [
    "training.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 55025 entries, 2905 to 78034\n",
      "Data columns (total 20 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   NUMBRANCH          55025 non-null  float64\n",
      " 1   UGDS               55025 non-null  float64\n",
      " 2   TUITFTE            55025 non-null  float64\n",
      " 3   INEXPFTE           55025 non-null  float64\n",
      " 4   PFTFAC             55025 non-null  float64\n",
      " 5   UG25abv            55025 non-null  float64\n",
      " 6   COMP_ORIG_YR4_RT   55025 non-null  float64\n",
      " 7   WDRAW_ORIG_YR4_RT  55025 non-null  float64\n",
      " 8   ENRL_ORIG_YR4_RT   55025 non-null  float64\n",
      " 9   DEBT_MDN           55025 non-null  float64\n",
      " 10  Year               55025 non-null  float64\n",
      " 11  Cost               55025 non-null  float64\n",
      " 12  Complete           55025 non-null  float64\n",
      " 13  RetentionFT        55025 non-null  float64\n",
      " 14  PREDDEG_1          55025 non-null  float64\n",
      " 15  PREDDEG_2          55025 non-null  float64\n",
      " 16  PREDDEG_3          55025 non-null  float64\n",
      " 17  PREDDEG_4          55025 non-null  float64\n",
      " 18  CONTROL_2.0        55025 non-null  float64\n",
      " 19  CONTROL_3.0        55025 non-null  float64\n",
      "dtypes: float64(20)\n",
      "memory usage: 8.8 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2905      True\n",
       "27743      NaN\n",
       "60310     True\n",
       "68067    False\n",
       "15350      NaN\n",
       "Name: CURROPER, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y_train.CURROPER.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling\n",
    "## Logistic Regression\n",
    "\n",
    "Hyperparameters to tune:\n",
    "- C - inverse of regularization strength; positive float; smaller values are stronger regularization, may lead to underfit model; large C may lead to overfitting\n",
    "- penalty (l1, l2, elasticnet, none) \n",
    "- l1_ratio - for elastic-net paramter mixing: l1_ratio = 0 == L2 penalty; l1_ratio = 1 == L1 penalty, so no need to use l1 and l2 as penalty parameters, since they will be encompassed in the elastic net values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and instantiate model\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameter search\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "c_grid = [0.001, 0.01, 0.1, 1, 10]\n",
    "pen_grid = ['elasticnet']\n",
    "l1_ratio_grid = [0, 0.1, 0.25, 0.5, 0.75, 0.9, 1]\n",
    "max_iter_grid = [100, 500, 1000, 1500, 2000]\n",
    "\n",
    "lr_grid = {'C':c_grid, 'penalty':pen_grid, 'l1_ratio':l1_ratio_grid,'max_iter':max_iter_grid}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: trying to use pen_grid = ['none', 'elasticnet'] led to errors, since the l1_ratio parameter is only valid for elastic net penatly, not none. If I want to train a model with no penalty, I will have to run a separate Grid search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(solver = 'saga')\n",
    "logreg_cv = RandomizedSearchCV(logreg, lr_grid, cv=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note - default solver 'lbfgs' can't handle elasticnet penalty.\n",
    "Note - with default max_iter = 100, kept getting ConvergenceWarning: The max_iter was reached which means the coef_ did not converge, so I added max_iter as a grid search parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start= time.time()\n",
    "logreg_cv.fit(X_train, y)\n",
    "end = time.time()\n",
    "print('GridSearch Time:', end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best params: \" , logreg_cv.best_params_)\n",
    "print(\"Best score: \", logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Results\n",
    "- Original run: l1_ratio=0.25, max_iter=2000, C=0.001\n",
    "- Second run: l1_ratio=1, max_iter= 2000, C=0.001\n",
    "- Third run: l1_ratio = 0.1, max_iter = 2000, C=0.01\n",
    "- Another run: l1_raio = 0.9, max_iter = 500, C=0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the model with the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelLR = LogisticRegression(C = 0.01, penalty = 'elasticnet', l1_ratio=0.1, max_iter = 2000, solver = 'saga')\n",
    "start = time.time()\n",
    "modelLR.fit(X_train, y)\n",
    "end = time.time()\n",
    "print(\"Fit time = \", end - start)\n",
    "\n",
    "start = time.time()\n",
    "lr_pred = modelLR.predict(X_test)\n",
    "end = time.time()\n",
    "print(\"Predict time = \", end - start)\n",
    "\n",
    "lr_pred_prob = modelLR.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model\n",
    "# Confusion matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(classification_report(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC curve\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "fpr, tpr, thresholds = roc_curve(y_test, lr_pred_prob)\n",
    "\n",
    "plt.plot( [0,1], [0,1], 'k--')\n",
    "plt.plot(fpr, tpr, label='Logistic Regression')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Logistic Regression ROC Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"AUC: \", roc_auc_score(y_test, lr_pred_prob))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coefficients\n",
    "coeffic = modelLR.coef_\n",
    "coeffic = coeffic[0]\n",
    "labels = [i for i in X_train.columns]\n",
    "numLab = len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffic = pd.DataFrame(coeffic, index=labels)\n",
    "coeffic.columns= ['Coefficient']\n",
    "coeffic.sort_values(by='Coefficient', inplace=True, ascending=False)\n",
    "coeffic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeffic.plot.bar(y='Coefficient')\n",
    "#plt.xticks(range(0, numLab), labels, rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient comments\n",
    "- Enrollment seems to be the most important predictor. [But it's worth checking how many values were imputed]\n",
    "- Year probably shouldn't be a predictor variable - it was included to distinguish the same schools across different years, to see at which point schools closed... (which I didn't actually explore)\n",
    "- Preddeg3 = Schools that offer predominantly bachelor's degrees (I think). I think this was the largest group of schools, so it may just be a data balance size issue. (May be predominantly graduate degrees)\n",
    "\n",
    "- Negative coefficient values\n",
    "-- Control3 = Private for profit school\n",
    "-- Control2 = Private nonprofit\n",
    "--(So does this mean that public schools have no effect, or positive coeff value?)\n",
    "- Withdraw\n",
    "- UG25abv "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree\n",
    "Parameters to search:\n",
    "- max_features\n",
    "- max_depth\n",
    "- min_samples_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_grid = ['gini', 'entropy']\n",
    "max_depth_grid = ['None', 3, 5, 10, 20, 50, 75, 100]\n",
    "min_sample_split_grid = [2, 5, 10, 25, 50, 75, 100]\n",
    "min_samples_leaf_grid = [2, 5, 10, 25, 50]\n",
    "feature_grid = [\"auto\", \"log2\", 4, 5, 10, 12, 15, 20]\n",
    "\n",
    "dtc_grid = {'criterion': criterion_grid, \n",
    "              'max_depth':max_depth_grid,\n",
    "              'min_samples_split':min_sample_split_grid,\n",
    "              'min_samples_leaf':min_samples_leaf_grid,\n",
    "              'max_features':feature_grid }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DecisionTreeClassifier()\n",
    "tree_cv = RandomizedSearchCV(tree, dtc_grid, cv=5)\n",
    "tree_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best params: \" , tree_cv.best_params_)\n",
    "print(\"Best score: \", tree_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Results\n",
    "- First run: min_sample_split=2; min_samples_leaf=25; max_features=20, max_depth=20, criterion=entropy\n",
    "- Second run: min_sample_split=75, min_samples_leaf=25; max_features=20, max_depth=20, criterion='entropy'\n",
    "- Another run: min_sample_split=100; min_samples_leaf=25; max_features=15; max_depth=50; criterion = entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore just the criterion and max_depth features, leaving the other arguments as the default. Plot the accuracy of different tree depths using both criterion measures.\n",
    "Code modified from https://towardsdatascience.com/decision-tree-build-prune-and-visualize-it-using-python-12ceee9af752"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "max_depth = []\n",
    "acc_gini = []\n",
    "acc_entropy = []\n",
    "for i in range(1, 31):\n",
    "    gtree = DecisionTreeClassifier(criterion='gini', max_depth=i)\n",
    "    gtree.fit(X_train, y_train)\n",
    "    gpredict = gtree.predict(X_test)\n",
    "    acc_gini.append(metrics.accuracy_score(y_test, gpredict))\n",
    "    ##\n",
    "    etree = DecisionTreeClassifier(criterion='entropy', max_depth=i)\n",
    "    etree.fit(X_train, y_train)\n",
    "    epredict = etree.predict(X_test)\n",
    "    acc_entropy.append(metrics.accuracy_score(y_test, epredict))\n",
    "    ##\n",
    "    max_depth.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = pd.DataFrame({'acc_gini':pd.Series(acc_gini),\n",
    "                     'acc_entropy':pd.Series(acc_entropy),\n",
    "                     'max_depth':pd.Series(max_depth)})\n",
    "\n",
    "plt.plot('max_depth', 'acc_gini', data=trees, label='gini')\n",
    "plt.plot('max_depth', 'acc_entropy', data=trees, label='entropy')\n",
    "#plt.vlines(12, 0.855, 0.880)\n",
    "plt.xlabel('max_depth')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the decision tree using the identified hyperparameters\n",
    "modelDT = DecisionTreeClassifier(criterion='gini', max_depth=12)\n",
    "modelDT.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.tree import plot_tree\n",
    "#plot_tree(modelDT)\n",
    "# Code from https://towardsdatascience.com/decision-tree-build-prune-and-visualize-it-using-python-12ceee9af752\n",
    "\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.externals.six import StringIO\n",
    "from IPython.display import Image\n",
    "import pydotplus\n",
    "\n",
    "dot_data = StringIO()\n",
    "export_graphviz(modelDT, out_file=dot_data, filled=True, feature_names=X_train.columns)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\n",
    "graph.write_png('tree.png')\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "plot_tree(modelDT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the trained tree to predict the testing data\n",
    "dt_pred = modelDT.predict(X_test)\n",
    "dt_pred_prob = modelDT.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this block for model evaluation \n",
    "#from sklearn import metrics\n",
    "print(\"Model Metrics\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, dt_pred))\n",
    "print(\"Balanced accuracy:\", metrics.balanced_accuracy_score(y_test, dt_pred))\n",
    "print('Precision score for \"Yes\"' , metrics.precision_score(y_test, dt_pred, pos_label = 1))\n",
    "print('Recall score for \"No\"' , metrics.recall_score(y_test, dt_pred, pos_label = 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, dt_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, dt_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "\n",
    "Hyperparameters:\n",
    "- number of features per tree\n",
    "- number of trees per forest (n_estimators)\n",
    "- depth(?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_tree_grid = [10,50,100,200,250,500]\n",
    "crit_grid = ['gini', 'entropy']\n",
    "max_depth_grid = ['None', 3, 5, 10, 15, 20]\n",
    "min_sample_split_grid = [2, 5, 10, 20]\n",
    "min_samples_leaf_grid = [2, 5, 10, 25, 50]\n",
    "feature_grid = [\"auto\", \"log2\", 4, 5, 10, 12, 15, 20]\n",
    "\n",
    "rfc_grid = {'n_estimators':n_tree_grid,\n",
    "              'criterion': crit_grid, \n",
    "              'max_depth':max_depth_grid,\n",
    "              'min_samples_split':min_sample_split_grid,\n",
    "              'min_samples_leaf':min_samples_leaf_grid,\n",
    "              'max_features':feature_grid }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier()\n",
    "start = time.time()\n",
    "forest_cv = RandomizedSearchCV(forest, rfc_grid, cv=5)\n",
    "forest_cv.fit(X_train, y)\n",
    "end = time.time()\n",
    "print(\"GridSearch time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best params: \" , forest_cv.best_params_)\n",
    "print(\"Best score: \", forest_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search Results\n",
    "- First run: n_estimators=200; min_sample_split=2; min_samples_leaf=2, max_features=10; max_depth=15; criterion='gini'\n",
    "- Second run: n_estimators=50; min_sample_split=5; min_samples_leaf=25; max_features=10; max_depth=10; criterion='gini'\n",
    "- Another run: n_estimators=10, split=10, leaf=5, features=12, depth=20, crit=entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose default for split, leaf; use 'auto' for max features, which will default to sqrt(n_feature), \n",
    "# max_depth is half of depth of single tree (above)\n",
    "modelRF = RandomForestClassifier(n_estimators = 100, max_features='auto',\n",
    "                                max_depth=6, criterion='gini')\n",
    "modelRF.fit(X_train, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred = modelRF.predict(X_test)\n",
    "rf_pred_prob = modelRF.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Random Forest Classifier model\")\n",
    "print(\"Accuracy:\", metrics.accuracy_score(y_test, rf_pred))\n",
    "print(\"Balanced accuracy:\", metrics.balanced_accuracy_score(y_test, rf_pred))\n",
    "print('Precision score for Yes' , metrics.precision_score(y_test, rf_pred, pos_label = 1))\n",
    "print('Recall score for No' , metrics.recall_score(y_test, rf_pred, pos_label = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, rf_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
